{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float32)\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "from scipy.stats import gamma, norm\n",
    "from darts.models import RNNModel,RegressionModel , RandomForest, XGBModel\n",
    "from darts.metrics import rmse, mape,mae, smape\n",
    "# from darts.utils.preprocessing import Scaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "# from darts.ad import ThresholdAD\n",
    "from darts import TimeSeries\n",
    "\n",
    "import pywt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.shapes import MSO_SHAPE\n",
    "from pptx.dml.color import RGBColor\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "\n",
    "Read and preprocess the input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b43e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path, parse_dates=[\"ds\"])\n",
    "    df.rename(columns={\n",
    "        \"ds\": \"date\",\n",
    "        \"precip\": \"rainfall\",\n",
    "        \"SPI_1\": \"spi1\",\n",
    "        \"SPI_3\": \"spi3\",\n",
    "        \"SPI_6\": \"spi6\",\n",
    "        \"SPI_9\": \"spi9\",\n",
    "        \"SPI_12\": \"spi12\",\n",
    "        \"SPI_24\": \"spi24\",\n",
    "        \"station_id\": \"station\"\n",
    "    }, inplace=True)\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_seasonality(series):\n",
    "    decomposition = seasonal_decompose(series, model='additive', period=12, extrapolate_trend='freq')\n",
    "    deseasonalized = series - decomposition.seasonal\n",
    "    return deseasonalized, decomposition.seasonal\n",
    "\n",
    "\n",
    "def make_features(df, timescale, lags=12):\n",
    "    # Use SPI timescale and rainfall as covariates\n",
    "    data = df[[f\"spi{timescale}\", \"rainfall\"]].copy()\n",
    "    data = data.rename(columns={f\"spi{timescale}\": \"spi\"})\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    # remove seasonality\n",
    "    # data['spi_deseason'] = remove_seasonality(data['spi'])\n",
    "    data['spi_deseason'], seasonal = remove_seasonality(data['spi'])\n",
    "    data['seasonal'] = seasonal\n",
    "\n",
    "    # lag features\n",
    "    for lag in range(1, lags+1):\n",
    "        data[f'spi_lag_{lag}'] = data['spi_deseason'].shift(lag)\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d6455",
   "metadata": {},
   "source": [
    "class TaylorDiagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f24f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TaylorDiagram:\n",
    "    def __init__(self, ref_std, fig=None, rect=111, label='Reference'):\n",
    "        self.ref_std = ref_std\n",
    "        self.sample_points = []\n",
    "\n",
    "        self.fig = fig if fig is not None else plt.figure(figsize=(8, 6))\n",
    "        self.ax = self.fig.add_subplot(rect, polar=True)\n",
    "\n",
    "        # Configure polar axes\n",
    "        self.ax.set_theta_zero_location('E')\n",
    "\n",
    "        self.ax.set_theta_direction(-1)\n",
    "        self.ax.set_theta_offset(np.pi / 2)\n",
    "        self.ax.set_ylim(0, 1.5 * ref_std)\n",
    "        self.ax.set_thetamin(0)\n",
    "        self.ax.set_thetamax(90)\n",
    "\n",
    "        # Set up correlation coefficient grid\n",
    "        self._setup_axes()\n",
    "\n",
    "        # Plot reference point\n",
    "        self.ax.plot([0], [ref_std], 'k*', markersize=12, label=label)\n",
    "\n",
    "    def _setup_axes(self):\n",
    "        corrs = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 0.9, 0.95, 0.99, 1.0])\n",
    "        angles = np.arccos(corrs)\n",
    "\n",
    "        self.ax.set_thetagrids(np.degrees(angles), labels=[f\"{c:.2f}\" for c in corrs], fontsize=10)\n",
    "        self.ax.set_rlabel_position(135)\n",
    "        self.ax.set_ylabel('Standard Deviation', fontsize=12)\n",
    "\n",
    "        # Add radial grid lines manually\n",
    "        for angle in angles:\n",
    "            self.ax.plot([angle, angle], [0, self.ax.get_ylim()[1]], color='lightgray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    def add_sample(self, stddev, corrcoef, label, marker='o', color=None):\n",
    "        theta = np.arccos(corrcoef)\n",
    "        point, = self.ax.plot(theta, stddev, marker=marker, label=label, color=color, markersize=8)\n",
    "        self.sample_points.append(point)\n",
    "\n",
    "    def add_contours(self, levels=6, cmap='coolwarm', linewidths=1.2):\n",
    "        rs, ts = np.meshgrid(\n",
    "            np.linspace(0, self.ax.get_ylim()[1], 300),\n",
    "            np.linspace(0, np.pi / 2, 300)\n",
    "        )\n",
    "        rms = np.sqrt(\n",
    "            self.ref_std**2 + rs**2 - 2 * self.ref_std * rs * np.cos(ts)\n",
    "        )\n",
    "        contours = self.ax.contour(\n",
    "            ts, rs, rms,\n",
    "            levels=np.linspace(0, self.ax.get_ylim()[1], levels),\n",
    "            cmap=cmap,\n",
    "            linewidths=linewidths\n",
    "        )\n",
    "        self.fig.colorbar(contours, ax=self.ax, pad=0.1, orientation='vertical', label=\"RMS Difference\")\n",
    "        return contours\n",
    "\n",
    "    def show(self, title='Taylor Diagram'):\n",
    "        self.ax.set_title(title, fontsize=14, pad=20)\n",
    "        self.ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f926e076",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "Define Models and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99bb81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WBBLSTMModel:\n",
    "\n",
    "    def __init__(self, wavelet='db1', level=2, **lstm_kwargs):\n",
    "        self.wavelet     = wavelet\n",
    "        self.level       = level\n",
    "        self.lstm_kwargs = lstm_kwargs\n",
    "\n",
    "    def _denoise(self, series: TimeSeries) -> TimeSeries:\n",
    "        arr    = series.values().flatten()\n",
    "        coeffs = pywt.wavedec(arr, self.wavelet, level=self.level)\n",
    "        # zero detail coeffs\n",
    "        for i in range(1, len(coeffs)):\n",
    "            coeffs[i] = np.zeros_like(coeffs[i])\n",
    "        denoised = pywt.waverec(coeffs, self.wavelet)\n",
    "        # trim padding if any\n",
    "        denoised = denoised[:len(series)]\n",
    "        return TimeSeries.from_times_and_values(\n",
    "            series.time_index,\n",
    "            denoised.reshape(-1,1).astype(np.float32)\n",
    "        )\n",
    "\n",
    "    def fit(self, series: TimeSeries, future_covariates: TimeSeries = None):\n",
    "        denoised = self._denoise(series)\n",
    "        self.lstm = RNNModel(model='LSTM', **self.lstm_kwargs)\n",
    "        # drop covariates completely\n",
    "        self.lstm.fit(denoised,future_covariates=future_covariates)\n",
    "\n",
    "    def predict(self, n, series: TimeSeries, future_covariates: TimeSeries = None):\n",
    "        denoised = self._denoise(series)\n",
    "        # predict only on the denoised series\n",
    "        return self.lstm.predict(n, series=denoised,future_covariates=future_covariates)\n",
    "\n",
    "    def save(self, path):\n",
    "            self.lstm.save(path)\n",
    "            meta = {'wavelet':self.wavelet, 'level':self.level, 'lstm_kwargs':self.lstm_kwargs}\n",
    "            with open(os.path.join(os.path.dirname(path),\"WBCovLSTMmeta.json\"),\"w\") as f:\n",
    "                json.dump(meta, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        meta = json.load(open(os.path.join(os.path.dirname(path),\"WBCovLSTMmeta.json\")))\n",
    "        inst = cls(wavelet=meta['wavelet'], level=meta['level'], **meta['lstm_kwargs'])\n",
    "        inst.lstm = RNNModel.load(path)\n",
    "        return inst\n",
    "\n",
    "\n",
    "window_size = 24\n",
    "num_epochs=150\n",
    "horizon = 1 \n",
    "\n",
    "\n",
    "model_constructors = {\n",
    "       'ExtraTF': lambda: XGBModel(\n",
    "         lags=window_size,\n",
    "        lags_future_covariates=[0],\n",
    "         output_chunk_length=horizon,\n",
    "         random_state=SEED,\n",
    "         objective='reg:squarederror'\n",
    "    ),\n",
    "    'RandomRF': lambda: RandomForest(\n",
    "         lags=window_size,\n",
    "         lags_future_covariates=[0],\n",
    "         output_chunk_length=horizon,\n",
    "         n_estimators=100,\n",
    "         criterion=\"absolute_error\",\n",
    "         random_state=SEED\n",
    "    ),\n",
    "    'SVR': lambda: RegressionModel(\n",
    "         model=SVR(kernel='rbf'),\n",
    "         lags_future_covariates=[0],\n",
    "         lags=window_size,\n",
    "         output_chunk_length=horizon\n",
    "    ),\n",
    "    'LSTM': lambda: RNNModel(\n",
    "         model='LSTM',\n",
    "         input_chunk_length=window_size,\n",
    "         output_chunk_length=horizon,\n",
    "         hidden_dim=32,\n",
    "         n_rnn_layers=1,\n",
    "         dropout=0.1,\n",
    "         batch_size=16,\n",
    "         n_epochs=num_epochs,\n",
    "         optimizer_kwargs={'lr':1e-3},\n",
    "         random_state=SEED\n",
    "    ),\n",
    "    'WBBLSTM'   : lambda: WBBLSTMModel(\n",
    "        wavelet='db1',\n",
    "        level=2,\n",
    "        input_chunk_length=window_size,\n",
    "        output_chunk_length=horizon,\n",
    "        hidden_dim=64,\n",
    "        n_rnn_layers=1,\n",
    "        dropout=0.1,\n",
    "        batch_size=16,\n",
    "        n_epochs=num_epochs,\n",
    "        optimizer_kwargs={'lr':1e-3},\n",
    "        random_state=SEED\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4fc8a",
   "metadata": {},
   "source": [
    "main loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16601ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station 40700 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40700/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40700/1\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40700/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40700/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40700/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
      "std_p: 0.71, corr: 0.84, rmse: 0.45, mae_v: 0.34,sm: 86.09 - ExtraTF \n",
      "std_p: 0.67, corr: 0.82, rmse: 0.47, mae_v: 0.35,sm: 77.02 - RandomRF \n",
      "std_p: 0.66, corr: 0.84, rmse: 0.45, mae_v: 0.32,sm: 70.36 - SVR \n",
      "std_p: 0.79, corr: 0.80, rmse: 0.51, mae_v: 0.40,sm: 90.80 - LSTM \n",
      "std_p: 0.27, corr: 0.24, rmse: 0.80, mae_v: 0.64,sm: 151.25 - WBBLSTM \n",
      "✔️ Done with 40700 | 1\n",
      "\n",
      "\n",
      "=== Station 40700 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40700/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40700/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40700/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40700/3\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40700/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n",
      "std_p: 0.65, corr: 0.45, rmse: 0.85, mae_v: 0.62,sm: 127.30 - ExtraTF \n",
      "std_p: 0.47, corr: 0.70, rmse: 0.62, mae_v: 0.39,sm: 99.44 - RandomRF \n",
      "std_p: 0.36, corr: 0.68, rmse: 0.67, mae_v: 0.42,sm: 101.98 - SVR \n",
      "std_p: 0.71, corr: 0.77, rmse: 0.56, mae_v: 0.39,sm: 93.63 - LSTM \n",
      "std_p: 0.50, corr: 0.28, rmse: 0.90, mae_v: 0.63,sm: 133.31 - WBBLSTM \n",
      "✔️ Done with 40700 | 3\n",
      "\n",
      "\n",
      "=== Station 40700 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40700/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40700/6\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40700/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40700/6\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40700/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s]\n",
      "std_p: 0.42, corr: 0.52, rmse: 0.70, mae_v: 0.56,sm: 117.47 - ExtraTF \n",
      "std_p: 0.55, corr: 0.86, rmse: 0.45, mae_v: 0.34,sm: 79.08 - RandomRF \n",
      "std_p: 0.42, corr: 0.88, rmse: 0.55, mae_v: 0.41,sm: 86.30 - SVR \n",
      "std_p: 0.73, corr: 0.89, rmse: 0.37, mae_v: 0.29,sm: 64.53 - LSTM \n",
      "std_p: 0.64, corr: 0.84, rmse: 0.46, mae_v: 0.38,sm: 85.08 - WBBLSTM \n",
      "✔️ Done with 40700 | 6\n",
      "\n",
      "\n",
      "=== Station 40700 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40700/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40700/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40700/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40700/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40700/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s]\n",
      "std_p: 0.44, corr: 0.55, rmse: 0.69, mae_v: 0.52,sm: 97.36 - ExtraTF \n",
      "std_p: 0.49, corr: 0.86, rmse: 0.47, mae_v: 0.35,sm: 67.43 - RandomRF \n",
      "std_p: 0.46, corr: 0.86, rmse: 0.55, mae_v: 0.41,sm: 88.30 - SVR \n",
      "std_p: 0.69, corr: 0.90, rmse: 0.36, mae_v: 0.28,sm: 63.66 - LSTM \n",
      "std_p: 0.63, corr: 0.82, rmse: 0.48, mae_v: 0.35,sm: 69.14 - WBBLSTM \n",
      "✔️ Done with 40700 | 9\n",
      "\n",
      "\n",
      "=== Station 40700 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40700/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40700/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40700/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40700/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40700/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s]\n",
      "std_p: 0.36, corr: 0.71, rmse: 0.59, mae_v: 0.47,sm: 80.09 - ExtraTF \n",
      "std_p: 0.49, corr: 0.91, rmse: 0.36, mae_v: 0.26,sm: 56.02 - RandomRF \n",
      "std_p: 0.41, corr: 0.79, rmse: 0.58, mae_v: 0.42,sm: 76.19 - SVR \n",
      "std_p: 0.64, corr: 0.93, rmse: 0.28, mae_v: 0.22,sm: 47.96 - LSTM \n",
      "std_p: 0.49, corr: 0.76, rmse: 0.53, mae_v: 0.39,sm: 75.15 - WBBLSTM \n",
      "✔️ Done with 40700 | 12\n",
      "\n",
      "\n",
      "=== Station 40700 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40700/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40700/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40700/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40700/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40700/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s]\n",
      "std_p: 0.18, corr: 0.37, rmse: 0.87, mae_v: 0.67,sm: 109.67 - ExtraTF \n",
      "std_p: 0.29, corr: 0.75, rmse: 0.48, mae_v: 0.31,sm: 41.60 - RandomRF \n",
      "std_p: 0.36, corr: 0.82, rmse: 0.48, mae_v: 0.36,sm: 54.65 - SVR \n",
      "std_p: 0.48, corr: 0.88, rmse: 0.31, mae_v: 0.23,sm: 39.03 - LSTM \n",
      "std_p: 0.49, corr: 0.79, rmse: 0.39, mae_v: 0.31,sm: 50.38 - WBBLSTM \n",
      "✔️ Done with 40700 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40701 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40701/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40701/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40701/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40701/1\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40701/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s]\n",
      "std_p: 0.75, corr: 0.83, rmse: 0.46, mae_v: 0.35,sm: 83.51 - ExtraTF \n",
      "std_p: 0.70, corr: 0.85, rmse: 0.44, mae_v: 0.32,sm: 79.41 - RandomRF \n",
      "std_p: 0.57, corr: 0.77, rmse: 0.53, mae_v: 0.37,sm: 81.69 - SVR \n",
      "std_p: 0.84, corr: 0.78, rmse: 0.54, mae_v: 0.45,sm: 91.42 - LSTM \n",
      "std_p: 0.35, corr: 0.30, rmse: 0.79, mae_v: 0.59,sm: 123.54 - WBBLSTM \n",
      "✔️ Done with 40701 | 1\n",
      "\n",
      "\n",
      "=== Station 40701 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40701/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40701/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40701/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40701/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40701/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.12it/s]\n",
      "std_p: 0.46, corr: 0.61, rmse: 0.62, mae_v: 0.45,sm: 115.84 - ExtraTF \n",
      "std_p: 0.46, corr: 0.73, rmse: 0.54, mae_v: 0.38,sm: 97.66 - RandomRF \n",
      "std_p: 0.32, corr: 0.65, rmse: 0.62, mae_v: 0.44,sm: 116.77 - SVR \n",
      "std_p: 0.62, corr: 0.63, rmse: 0.61, mae_v: 0.46,sm: 117.67 - LSTM \n",
      "std_p: 0.49, corr: 0.54, rmse: 0.65, mae_v: 0.45,sm: 111.44 - WBBLSTM \n",
      "✔️ Done with 40701 | 3\n",
      "\n",
      "\n",
      "=== Station 40701 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40701/6\\ExtraTF…\n",
      "negative corr\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40701/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40701/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40701/6\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40701/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "std_p: 0.48, corr: 0.00, rmse: 0.91, mae_v: 0.70,sm: 139.91 - ExtraTF \n",
      "std_p: 0.58, corr: 0.88, rmse: 0.39, mae_v: 0.31,sm: 72.97 - RandomRF \n",
      "std_p: 0.35, corr: 0.81, rmse: 0.54, mae_v: 0.43,sm: 104.00 - SVR \n",
      "std_p: 0.80, corr: 0.93, rmse: 0.30, mae_v: 0.24,sm: 61.46 - LSTM \n",
      "std_p: 0.63, corr: 0.81, rmse: 0.46, mae_v: 0.38,sm: 86.75 - WBBLSTM \n",
      "✔️ Done with 40701 | 6\n",
      "\n",
      "\n",
      "=== Station 40701 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40701/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40701/9\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40701/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40701/9\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40701/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "std_p: 0.63, corr: 0.02, rmse: 1.25, mae_v: 0.95,sm: 120.65 - ExtraTF \n",
      "std_p: 0.70, corr: 0.93, rmse: 0.36, mae_v: 0.28,sm: 53.82 - RandomRF \n",
      "std_p: 0.49, corr: 0.86, rmse: 0.56, mae_v: 0.44,sm: 81.68 - SVR \n",
      "std_p: 0.92, corr: 0.90, rmse: 0.43, mae_v: 0.35,sm: 63.78 - LSTM \n",
      "std_p: 0.88, corr: 0.93, rmse: 0.34, mae_v: 0.28,sm: 57.57 - WBBLSTM \n",
      "✔️ Done with 40701 | 9\n",
      "\n",
      "\n",
      "=== Station 40701 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40701/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40701/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40701/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40701/12\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40701/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s]\n",
      "std_p: 0.46, corr: 0.15, rmse: 1.35, mae_v: 1.23,sm: 156.84 - ExtraTF \n",
      "std_p: 0.95, corr: 0.91, rmse: 0.47, mae_v: 0.37,sm: 56.02 - RandomRF \n",
      "std_p: 0.66, corr: 0.84, rmse: 0.66, mae_v: 0.52,sm: 83.26 - SVR \n",
      "std_p: 1.04, corr: 0.95, rmse: 0.35, mae_v: 0.28,sm: 50.21 - LSTM \n",
      "std_p: 1.00, corr: 0.92, rmse: 0.44, mae_v: 0.33,sm: 54.72 - WBBLSTM \n",
      "✔️ Done with 40701 | 12\n",
      "\n",
      "\n",
      "=== Station 40701 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40701/24\\ExtraTF…\n",
      "negative corr\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40701/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40701/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40701/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40701/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s]\n",
      "std_p: 0.84, corr: 0.47, rmse: 1.62, mae_v: 1.32,sm: 123.41 - ExtraTF \n",
      "std_p: 0.99, corr: 0.95, rmse: 0.33, mae_v: 0.24,sm: 38.70 - RandomRF \n",
      "std_p: 0.75, corr: 0.87, rmse: 0.53, mae_v: 0.46,sm: 81.53 - SVR \n",
      "std_p: 1.05, corr: 0.97, rmse: 0.30, mae_v: 0.23,sm: 40.04 - LSTM \n",
      "std_p: 1.03, corr: 0.94, rmse: 0.36, mae_v: 0.24,sm: 40.41 - WBBLSTM \n",
      "✔️ Done with 40701 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40704 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40704/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40704/1\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40704/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40704/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40704/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s]\n",
      "std_p: 0.60, corr: 0.71, rmse: 0.52, mae_v: 0.41,sm: 100.68 - ExtraTF \n",
      "std_p: 0.54, corr: 0.70, rmse: 0.51, mae_v: 0.42,sm: 102.75 - RandomRF \n",
      "std_p: 0.56, corr: 0.69, rmse: 0.53, mae_v: 0.41,sm: 97.00 - SVR \n",
      "std_p: 0.74, corr: 0.81, rmse: 0.45, mae_v: 0.35,sm: 80.83 - LSTM \n",
      "std_p: 0.32, corr: 0.36, rmse: 0.67, mae_v: 0.56,sm: 145.09 - WBBLSTM \n",
      "✔️ Done with 40704 | 1\n",
      "\n",
      "\n",
      "=== Station 40704 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40704/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40704/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40704/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40704/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40704/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s]\n",
      "std_p: 0.50, corr: 0.64, rmse: 0.53, mae_v: 0.42,sm: 101.06 - ExtraTF \n",
      "std_p: 0.44, corr: 0.79, rmse: 0.43, mae_v: 0.35,sm: 90.57 - RandomRF \n",
      "std_p: 0.30, corr: 0.72, rmse: 0.52, mae_v: 0.42,sm: 110.86 - SVR \n",
      "std_p: 0.62, corr: 0.72, rmse: 0.49, mae_v: 0.37,sm: 93.90 - LSTM \n",
      "std_p: 0.41, corr: 0.59, rmse: 0.55, mae_v: 0.43,sm: 106.65 - WBBLSTM \n",
      "✔️ Done with 40704 | 3\n",
      "\n",
      "\n",
      "=== Station 40704 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40704/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40704/6\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40704/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40704/6\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40704/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
      "std_p: 0.59, corr: 0.73, rmse: 0.63, mae_v: 0.51,sm: 103.82 - ExtraTF \n",
      "std_p: 0.59, corr: 0.90, rmse: 0.44, mae_v: 0.36,sm: 84.40 - RandomRF \n",
      "std_p: 0.38, corr: 0.87, rmse: 0.60, mae_v: 0.46,sm: 102.36 - SVR \n",
      "std_p: 0.79, corr: 0.92, rmse: 0.35, mae_v: 0.28,sm: 77.13 - LSTM \n",
      "std_p: 0.72, corr: 0.89, rmse: 0.41, mae_v: 0.32,sm: 77.10 - WBBLSTM \n",
      "✔️ Done with 40704 | 6\n",
      "\n",
      "\n",
      "=== Station 40704 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40704/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40704/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40704/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40704/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40704/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s]\n",
      "std_p: 0.68, corr: 0.49, rmse: 0.94, mae_v: 0.78,sm: 126.87 - ExtraTF \n",
      "std_p: 0.66, corr: 0.86, rmse: 0.55, mae_v: 0.42,sm: 71.10 - RandomRF \n",
      "std_p: 0.49, corr: 0.85, rmse: 0.65, mae_v: 0.50,sm: 87.71 - SVR \n",
      "std_p: 0.84, corr: 0.86, rmse: 0.50, mae_v: 0.41,sm: 83.11 - LSTM \n",
      "std_p: 0.74, corr: 0.87, rmse: 0.51, mae_v: 0.40,sm: 78.84 - WBBLSTM \n",
      "✔️ Done with 40704 | 9\n",
      "\n",
      "\n",
      "=== Station 40704 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40704/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40704/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40704/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40704/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40704/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s]\n",
      "std_p: 0.72, corr: 0.45, rmse: 1.04, mae_v: 0.76,sm: 103.92 - ExtraTF \n",
      "std_p: 0.86, corr: 0.89, rmse: 0.51, mae_v: 0.38,sm: 59.39 - RandomRF \n",
      "std_p: 0.66, corr: 0.82, rmse: 0.67, mae_v: 0.52,sm: 90.40 - SVR \n",
      "std_p: 0.87, corr: 0.92, rmse: 0.47, mae_v: 0.35,sm: 55.06 - LSTM \n",
      "std_p: 0.89, corr: 0.85, rmse: 0.59, mae_v: 0.44,sm: 69.38 - WBBLSTM \n",
      "✔️ Done with 40704 | 12\n",
      "\n",
      "\n",
      "=== Station 40704 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40704/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40704/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40704/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40704/24\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40704/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s]\n",
      "std_p: 0.82, corr: 0.70, rmse: 0.72, mae_v: 0.55,sm: 98.63 - ExtraTF \n",
      "std_p: 0.89, corr: 0.95, rmse: 0.30, mae_v: 0.25,sm: 50.68 - RandomRF \n",
      "std_p: 0.66, corr: 0.87, rmse: 0.55, mae_v: 0.40,sm: 72.01 - SVR \n",
      "std_p: 0.95, corr: 0.96, rmse: 0.29, mae_v: 0.22,sm: 57.26 - LSTM \n",
      "std_p: 0.90, corr: 0.95, rmse: 0.30, mae_v: 0.23,sm: 54.20 - WBBLSTM \n",
      "✔️ Done with 40704 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40705 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40705/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40705/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40705/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40705/1\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40705/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s]\n",
      "std_p: 0.71, corr: 0.71, rmse: 0.54, mae_v: 0.42,sm: 100.97 - ExtraTF \n",
      "std_p: 0.65, corr: 0.76, rmse: 0.48, mae_v: 0.36,sm: 83.51 - RandomRF \n",
      "std_p: 0.61, corr: 0.75, rmse: 0.47, mae_v: 0.35,sm: 75.85 - SVR \n",
      "std_p: 0.74, corr: 0.77, rmse: 0.51, mae_v: 0.42,sm: 99.76 - LSTM \n",
      "std_p: 0.31, corr: 0.46, rmse: 0.63, mae_v: 0.52,sm: 131.22 - WBBLSTM \n",
      "✔️ Done with 40705 | 1\n",
      "\n",
      "\n",
      "=== Station 40705 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40705/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40705/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40705/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40705/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40705/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s]\n",
      "std_p: 0.68, corr: 0.53, rmse: 0.65, mae_v: 0.54,sm: 120.67 - ExtraTF \n",
      "std_p: 0.51, corr: 0.78, rmse: 0.42, mae_v: 0.33,sm: 94.34 - RandomRF \n",
      "std_p: 0.36, corr: 0.58, rmse: 0.53, mae_v: 0.44,sm: 121.06 - SVR \n",
      "std_p: 0.73, corr: 0.75, rmse: 0.54, mae_v: 0.42,sm: 94.91 - LSTM \n",
      "std_p: 0.49, corr: 0.68, rmse: 0.49, mae_v: 0.37,sm: 100.14 - WBBLSTM \n",
      "✔️ Done with 40705 | 3\n",
      "\n",
      "\n",
      "=== Station 40705 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40705/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40705/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40705/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40705/6\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40705/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s]\n",
      "std_p: 0.60, corr: 0.48, rmse: 0.76, mae_v: 0.58,sm: 116.85 - ExtraTF \n",
      "std_p: 0.61, corr: 0.85, rmse: 0.42, mae_v: 0.31,sm: 92.92 - RandomRF \n",
      "std_p: 0.31, corr: 0.73, rmse: 0.60, mae_v: 0.43,sm: 113.99 - SVR \n",
      "std_p: 0.79, corr: 0.86, rmse: 0.41, mae_v: 0.31,sm: 86.11 - LSTM \n",
      "std_p: 0.56, corr: 0.81, rmse: 0.47, mae_v: 0.39,sm: 99.56 - WBBLSTM \n",
      "✔️ Done with 40705 | 6\n",
      "\n",
      "\n",
      "=== Station 40705 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40705/9\\ExtraTF…\n",
      "negative corr\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40705/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40705/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40705/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40705/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s]\n",
      "std_p: 0.85, corr: 0.29, rmse: 1.10, mae_v: 0.93,sm: 131.58 - ExtraTF \n",
      "std_p: 0.68, corr: 0.87, rmse: 0.41, mae_v: 0.32,sm: 84.80 - RandomRF \n",
      "std_p: 0.31, corr: 0.75, rmse: 0.63, mae_v: 0.45,sm: 108.45 - SVR \n",
      "std_p: 0.77, corr: 0.86, rmse: 0.44, mae_v: 0.36,sm: 88.63 - LSTM \n",
      "std_p: 0.61, corr: 0.81, rmse: 0.49, mae_v: 0.36,sm: 79.24 - WBBLSTM \n",
      "✔️ Done with 40705 | 9\n",
      "\n",
      "\n",
      "=== Station 40705 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40705/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40705/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40705/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40705/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40705/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s]\n",
      "std_p: 0.99, corr: 0.72, rmse: 0.76, mae_v: 0.63,sm: 110.66 - ExtraTF \n",
      "std_p: 0.77, corr: 0.85, rmse: 0.47, mae_v: 0.36,sm: 89.16 - RandomRF \n",
      "std_p: 0.47, corr: 0.69, rmse: 0.64, mae_v: 0.48,sm: 107.43 - SVR \n",
      "std_p: 0.92, corr: 0.87, rmse: 0.46, mae_v: 0.36,sm: 86.04 - LSTM \n",
      "std_p: 0.83, corr: 0.83, rmse: 0.50, mae_v: 0.39,sm: 90.86 - WBBLSTM \n",
      "✔️ Done with 40705 | 12\n",
      "\n",
      "\n",
      "=== Station 40705 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40705/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40705/24\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40705/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40705/24\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40705/24\\WBBLSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s]\n",
      "std_p: 0.41, corr: 0.07, rmse: 1.13, mae_v: 0.93,sm: 146.62 - ExtraTF \n",
      "std_p: 0.74, corr: 0.92, rmse: 0.29, mae_v: 0.24,sm: 59.22 - RandomRF \n",
      "std_p: 0.50, corr: 0.83, rmse: 0.45, mae_v: 0.34,sm: 76.79 - SVR \n",
      "std_p: 0.87, corr: 0.89, rmse: 0.40, mae_v: 0.33,sm: 73.65 - LSTM \n",
      "std_p: 0.69, corr: 0.92, rmse: 0.31, mae_v: 0.25,sm: 70.24 - WBBLSTM \n",
      "✔️ Done with 40705 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40706 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40706/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40706/1\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40706/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40706/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40706/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s]\n",
      "std_p: 0.50, corr: 0.73, rmse: 0.47, mae_v: 0.36,sm: 88.58 - ExtraTF \n",
      "std_p: 0.46, corr: 0.73, rmse: 0.47, mae_v: 0.37,sm: 93.80 - RandomRF \n",
      "std_p: 0.48, corr: 0.66, rmse: 0.53, mae_v: 0.40,sm: 93.99 - SVR \n",
      "std_p: 0.63, corr: 0.68, rmse: 0.53, mae_v: 0.43,sm: 102.92 - LSTM \n",
      "std_p: 0.31, corr: 0.23, rmse: 0.70, mae_v: 0.53,sm: 134.25 - WBBLSTM \n",
      "✔️ Done with 40706 | 1\n",
      "\n",
      "\n",
      "=== Station 40706 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40706/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40706/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40706/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40706/3\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40706/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s]\n",
      "std_p: 0.50, corr: 0.47, rmse: 0.58, mae_v: 0.46,sm: 120.64 - ExtraTF \n",
      "std_p: 0.37, corr: 0.66, rmse: 0.44, mae_v: 0.35,sm: 107.67 - RandomRF \n",
      "std_p: 0.28, corr: 0.65, rmse: 0.46, mae_v: 0.37,sm: 119.90 - SVR \n",
      "std_p: 0.56, corr: 0.80, rmse: 0.37, mae_v: 0.29,sm: 87.73 - LSTM \n",
      "std_p: 0.39, corr: 0.33, rmse: 0.59, mae_v: 0.48,sm: 125.17 - WBBLSTM \n",
      "✔️ Done with 40706 | 3\n",
      "\n",
      "\n",
      "=== Station 40706 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40706/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40706/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40706/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40706/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40706/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s]\n",
      "std_p: 0.50, corr: 0.60, rmse: 0.59, mae_v: 0.49,sm: 110.87 - ExtraTF \n",
      "std_p: 0.55, corr: 0.86, rmse: 0.40, mae_v: 0.34,sm: 88.56 - RandomRF \n",
      "std_p: 0.31, corr: 0.88, rmse: 0.48, mae_v: 0.40,sm: 101.34 - SVR \n",
      "std_p: 0.63, corr: 0.91, rmse: 0.31, mae_v: 0.25,sm: 75.40 - LSTM \n",
      "std_p: 0.60, corr: 0.83, rmse: 0.41, mae_v: 0.34,sm: 87.76 - WBBLSTM \n",
      "✔️ Done with 40706 | 6\n",
      "\n",
      "\n",
      "=== Station 40706 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40706/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40706/9\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40706/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40706/9\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40706/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
      "std_p: 0.60, corr: 0.52, rmse: 0.80, mae_v: 0.67,sm: 115.66 - ExtraTF \n",
      "std_p: 0.68, corr: 0.89, rmse: 0.44, mae_v: 0.37,sm: 73.36 - RandomRF \n",
      "std_p: 0.43, corr: 0.89, rmse: 0.58, mae_v: 0.49,sm: 98.46 - SVR \n",
      "std_p: 0.81, corr: 0.90, rmse: 0.40, mae_v: 0.32,sm: 62.26 - LSTM \n",
      "std_p: 0.77, corr: 0.82, rmse: 0.54, mae_v: 0.41,sm: 75.99 - WBBLSTM \n",
      "✔️ Done with 40706 | 9\n",
      "\n",
      "\n",
      "=== Station 40706 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40706/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40706/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40706/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40706/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40706/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s]\n",
      "std_p: 0.67, corr: 0.82, rmse: 0.72, mae_v: 0.59,sm: 87.51 - ExtraTF \n",
      "std_p: 0.90, corr: 0.92, rmse: 0.46, mae_v: 0.38,sm: 66.77 - RandomRF \n",
      "std_p: 0.66, corr: 0.89, rmse: 0.61, mae_v: 0.51,sm: 82.95 - SVR \n",
      "std_p: 0.94, corr: 0.92, rmse: 0.44, mae_v: 0.36,sm: 65.54 - LSTM \n",
      "std_p: 0.89, corr: 0.90, rmse: 0.50, mae_v: 0.39,sm: 68.19 - WBBLSTM \n",
      "✔️ Done with 40706 | 12\n",
      "\n",
      "\n",
      "=== Station 40706 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40706/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40706/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40706/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40706/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40706/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s]\n",
      "std_p: 0.46, corr: 0.47, rmse: 1.06, mae_v: 0.88,sm: 116.33 - ExtraTF \n",
      "std_p: 0.93, corr: 0.94, rmse: 0.39, mae_v: 0.31,sm: 41.77 - RandomRF \n",
      "std_p: 0.66, corr: 0.90, rmse: 0.59, mae_v: 0.48,sm: 67.73 - SVR \n",
      "std_p: 0.94, corr: 0.94, rmse: 0.44, mae_v: 0.37,sm: 58.22 - LSTM \n",
      "std_p: 0.86, corr: 0.89, rmse: 0.55, mae_v: 0.42,sm: 70.29 - WBBLSTM \n",
      "✔️ Done with 40706 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40708 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40708/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40708/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40708/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40708/1\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40708/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.67it/s]\n",
      "std_p: 0.64, corr: 0.76, rmse: 0.45, mae_v: 0.36,sm: 90.95 - ExtraTF \n",
      "std_p: 0.54, corr: 0.77, rmse: 0.43, mae_v: 0.34,sm: 100.37 - RandomRF \n",
      "std_p: 0.50, corr: 0.74, rmse: 0.44, mae_v: 0.36,sm: 94.76 - SVR \n",
      "std_p: 0.73, corr: 0.77, rmse: 0.48, mae_v: 0.39,sm: 95.16 - LSTM \n",
      "std_p: 0.33, corr: 0.29, rmse: 0.65, mae_v: 0.52,sm: 140.95 - WBBLSTM \n",
      "✔️ Done with 40708 | 1\n",
      "\n",
      "\n",
      "=== Station 40708 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40708/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40708/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40708/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40708/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40708/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s]\n",
      "std_p: 0.50, corr: 0.63, rmse: 0.49, mae_v: 0.39,sm: 111.25 - ExtraTF \n",
      "std_p: 0.41, corr: 0.80, rmse: 0.37, mae_v: 0.30,sm: 93.22 - RandomRF \n",
      "std_p: 0.29, corr: 0.64, rmse: 0.48, mae_v: 0.37,sm: 115.25 - SVR \n",
      "std_p: 0.58, corr: 0.77, rmse: 0.40, mae_v: 0.33,sm: 97.48 - LSTM \n",
      "std_p: 0.38, corr: 0.51, rmse: 0.53, mae_v: 0.41,sm: 120.17 - WBBLSTM \n",
      "✔️ Done with 40708 | 3\n",
      "\n",
      "\n",
      "=== Station 40708 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40708/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40708/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40708/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40708/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40708/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s]\n",
      "std_p: 0.62, corr: 0.60, rmse: 0.80, mae_v: 0.69,sm: 133.33 - ExtraTF \n",
      "std_p: 0.49, corr: 0.84, rmse: 0.44, mae_v: 0.34,sm: 84.09 - RandomRF \n",
      "std_p: 0.35, corr: 0.78, rmse: 0.57, mae_v: 0.44,sm: 101.54 - SVR \n",
      "std_p: 0.81, corr: 0.88, rmse: 0.38, mae_v: 0.30,sm: 73.98 - LSTM \n",
      "std_p: 0.56, corr: 0.83, rmse: 0.46, mae_v: 0.34,sm: 80.40 - WBBLSTM \n",
      "✔️ Done with 40708 | 6\n",
      "\n",
      "\n",
      "=== Station 40708 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40708/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40708/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40708/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40708/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40708/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s]\n",
      "std_p: 0.61, corr: 0.31, rmse: 0.86, mae_v: 0.69,sm: 124.31 - ExtraTF \n",
      "std_p: 0.53, corr: 0.85, rmse: 0.47, mae_v: 0.36,sm: 73.09 - RandomRF \n",
      "std_p: 0.37, corr: 0.81, rmse: 0.60, mae_v: 0.46,sm: 98.76 - SVR \n",
      "std_p: 0.63, corr: 0.83, rmse: 0.48, mae_v: 0.36,sm: 77.98 - LSTM \n",
      "std_p: 0.59, corr: 0.68, rmse: 0.61, mae_v: 0.44,sm: 80.33 - WBBLSTM \n",
      "✔️ Done with 40708 | 9\n",
      "\n",
      "\n",
      "=== Station 40708 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40708/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40708/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40708/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40708/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40708/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s]\n",
      "std_p: 0.66, corr: 0.57, rmse: 0.75, mae_v: 0.59,sm: 101.07 - ExtraTF \n",
      "std_p: 0.55, corr: 0.82, rmse: 0.49, mae_v: 0.37,sm: 75.48 - RandomRF \n",
      "std_p: 0.43, corr: 0.70, rmse: 0.66, mae_v: 0.50,sm: 101.39 - SVR \n",
      "std_p: 0.77, corr: 0.88, rmse: 0.38, mae_v: 0.32,sm: 65.34 - LSTM \n",
      "std_p: 0.67, corr: 0.86, rmse: 0.44, mae_v: 0.33,sm: 74.81 - WBBLSTM \n",
      "✔️ Done with 40708 | 12\n",
      "\n",
      "\n",
      "=== Station 40708 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40708/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40708/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40708/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40708/24\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40708/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s]\n",
      "std_p: 0.45, corr: 0.63, rmse: 0.56, mae_v: 0.45,sm: 74.75 - ExtraTF \n",
      "std_p: 0.53, corr: 0.91, rmse: 0.34, mae_v: 0.27,sm: 51.84 - RandomRF \n",
      "std_p: 0.38, corr: 0.81, rmse: 0.53, mae_v: 0.40,sm: 74.63 - SVR \n",
      "std_p: 0.56, corr: 0.76, rmse: 0.47, mae_v: 0.38,sm: 74.37 - LSTM \n",
      "std_p: 0.46, corr: 0.77, rmse: 0.48, mae_v: 0.38,sm: 69.09 - WBBLSTM \n",
      "✔️ Done with 40708 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40710 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40710/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40710/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40710/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40710/1\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40710/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s]\n",
      "std_p: 0.73, corr: 0.74, rmse: 0.52, mae_v: 0.41,sm: 89.22 - ExtraTF \n",
      "std_p: 0.63, corr: 0.74, rmse: 0.49, mae_v: 0.39,sm: 87.10 - RandomRF \n",
      "std_p: 0.62, corr: 0.72, rmse: 0.51, mae_v: 0.40,sm: 87.83 - SVR \n",
      "std_p: 0.81, corr: 0.65, rmse: 0.64, mae_v: 0.51,sm: 92.98 - LSTM \n",
      "std_p: 0.30, corr: 0.27, rmse: 0.69, mae_v: 0.57,sm: 137.06 - WBBLSTM \n",
      "✔️ Done with 40710 | 1\n",
      "\n",
      "\n",
      "=== Station 40710 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40710/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40710/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40710/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40710/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40710/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s]\n",
      "std_p: 0.62, corr: 0.49, rmse: 0.59, mae_v: 0.50,sm: 123.60 - ExtraTF \n",
      "std_p: 0.40, corr: 0.61, rmse: 0.42, mae_v: 0.35,sm: 106.33 - RandomRF \n",
      "std_p: 0.35, corr: 0.57, rmse: 0.44, mae_v: 0.35,sm: 107.80 - SVR \n",
      "std_p: 0.71, corr: 0.71, rmse: 0.50, mae_v: 0.40,sm: 103.35 - LSTM \n",
      "std_p: 0.55, corr: 0.38, rmse: 0.60, mae_v: 0.47,sm: 121.51 - WBBLSTM \n",
      "✔️ Done with 40710 | 3\n",
      "\n",
      "\n",
      "=== Station 40710 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40710/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40710/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40710/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40710/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40710/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
      "std_p: 0.70, corr: 0.72, rmse: 0.57, mae_v: 0.46,sm: 100.89 - ExtraTF \n",
      "std_p: 0.50, corr: 0.80, rmse: 0.39, mae_v: 0.31,sm: 88.84 - RandomRF \n",
      "std_p: 0.42, corr: 0.81, rmse: 0.41, mae_v: 0.33,sm: 91.55 - SVR \n",
      "std_p: 0.71, corr: 0.85, rmse: 0.38, mae_v: 0.31,sm: 78.78 - LSTM \n",
      "std_p: 0.57, corr: 0.77, rmse: 0.42, mae_v: 0.33,sm: 92.94 - WBBLSTM \n",
      "✔️ Done with 40710 | 6\n",
      "\n",
      "\n",
      "=== Station 40710 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40710/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40710/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40710/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40710/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40710/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s]\n",
      "std_p: 0.60, corr: 0.40, rmse: 0.82, mae_v: 0.61,sm: 132.02 - ExtraTF \n",
      "std_p: 0.51, corr: 0.81, rmse: 0.46, mae_v: 0.38,sm: 107.47 - RandomRF \n",
      "std_p: 0.43, corr: 0.86, rmse: 0.48, mae_v: 0.40,sm: 117.32 - SVR \n",
      "std_p: 0.69, corr: 0.87, rmse: 0.38, mae_v: 0.31,sm: 81.41 - LSTM \n",
      "std_p: 0.71, corr: 0.83, rmse: 0.43, mae_v: 0.35,sm: 85.71 - WBBLSTM \n",
      "✔️ Done with 40710 | 9\n",
      "\n",
      "\n",
      "=== Station 40710 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40710/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40710/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40710/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40710/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40710/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]\n",
      "std_p: 0.82, corr: 0.72, rmse: 0.92, mae_v: 0.78,sm: 131.21 - ExtraTF \n",
      "std_p: 0.57, corr: 0.83, rmse: 0.47, mae_v: 0.38,sm: 96.59 - RandomRF \n",
      "std_p: 0.51, corr: 0.78, rmse: 0.55, mae_v: 0.42,sm: 101.41 - SVR \n",
      "std_p: 0.73, corr: 0.82, rmse: 0.47, mae_v: 0.36,sm: 86.12 - LSTM \n",
      "std_p: 0.74, corr: 0.76, rmse: 0.54, mae_v: 0.42,sm: 85.71 - WBBLSTM \n",
      "✔️ Done with 40710 | 12\n",
      "\n",
      "\n",
      "=== Station 40710 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40710/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40710/24\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40710/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40710/24\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40710/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n",
      "std_p: 0.98, corr: 0.71, rmse: 0.73, mae_v: 0.60,sm: 111.86 - ExtraTF \n",
      "std_p: 0.83, corr: 0.89, rmse: 0.38, mae_v: 0.31,sm: 81.86 - RandomRF \n",
      "std_p: 0.56, corr: 0.87, rmse: 0.43, mae_v: 0.34,sm: 84.56 - SVR \n",
      "std_p: 0.68, corr: 0.91, rmse: 0.33, mae_v: 0.27,sm: 77.67 - LSTM \n",
      "std_p: 0.58, corr: 0.80, rmse: 0.46, mae_v: 0.38,sm: 89.90 - WBBLSTM \n",
      "✔️ Done with 40710 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40712 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40712/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40712/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40712/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40712/1\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40712/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s]\n",
      "std_p: 0.52, corr: 0.69, rmse: 0.46, mae_v: 0.35,sm: 86.19 - ExtraTF \n",
      "std_p: 0.49, corr: 0.72, rmse: 0.43, mae_v: 0.32,sm: 78.91 - RandomRF \n",
      "std_p: 0.48, corr: 0.69, rmse: 0.45, mae_v: 0.33,sm: 80.21 - SVR \n",
      "std_p: 0.72, corr: 0.78, rmse: 0.45, mae_v: 0.34,sm: 81.03 - LSTM \n",
      "std_p: 0.33, corr: 0.24, rmse: 0.62, mae_v: 0.49,sm: 131.77 - WBBLSTM \n",
      "✔️ Done with 40712 | 1\n",
      "\n",
      "\n",
      "=== Station 40712 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40712/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40712/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40712/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40712/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40712/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
      "std_p: 0.50, corr: 0.65, rmse: 0.44, mae_v: 0.34,sm: 100.90 - ExtraTF \n",
      "std_p: 0.36, corr: 0.74, rmse: 0.38, mae_v: 0.31,sm: 101.44 - RandomRF \n",
      "std_p: 0.29, corr: 0.65, rmse: 0.42, mae_v: 0.34,sm: 115.71 - SVR \n",
      "std_p: 0.55, corr: 0.78, rmse: 0.36, mae_v: 0.29,sm: 91.88 - LSTM \n",
      "std_p: 0.42, corr: 0.68, rmse: 0.42, mae_v: 0.34,sm: 110.24 - WBBLSTM \n",
      "✔️ Done with 40712 | 3\n",
      "\n",
      "\n",
      "=== Station 40712 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40712/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40712/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40712/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40712/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40712/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s]\n",
      "std_p: 0.47, corr: 0.71, rmse: 0.55, mae_v: 0.42,sm: 108.83 - ExtraTF \n",
      "std_p: 0.47, corr: 0.88, rmse: 0.38, mae_v: 0.29,sm: 85.42 - RandomRF \n",
      "std_p: 0.37, corr: 0.83, rmse: 0.46, mae_v: 0.35,sm: 98.19 - SVR \n",
      "std_p: 0.65, corr: 0.90, rmse: 0.31, mae_v: 0.23,sm: 74.87 - LSTM \n",
      "std_p: 0.66, corr: 0.78, rmse: 0.48, mae_v: 0.38,sm: 90.42 - WBBLSTM \n",
      "✔️ Done with 40712 | 6\n",
      "\n",
      "\n",
      "=== Station 40712 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40712/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40712/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40712/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40712/9\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40712/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s]\n",
      "std_p: 0.54, corr: 0.56, rmse: 0.73, mae_v: 0.59,sm: 110.08 - ExtraTF \n",
      "std_p: 0.74, corr: 0.91, rmse: 0.37, mae_v: 0.28,sm: 49.19 - RandomRF \n",
      "std_p: 0.49, corr: 0.86, rmse: 0.53, mae_v: 0.42,sm: 80.64 - SVR \n",
      "std_p: 0.86, corr: 0.96, rmse: 0.26, mae_v: 0.21,sm: 48.14 - LSTM \n",
      "std_p: 0.85, corr: 0.90, rmse: 0.38, mae_v: 0.30,sm: 63.48 - WBBLSTM \n",
      "✔️ Done with 40712 | 9\n",
      "\n",
      "\n",
      "=== Station 40712 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40712/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40712/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40712/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40712/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40712/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n",
      "std_p: 0.47, corr: 0.72, rmse: 0.81, mae_v: 0.66,sm: 121.42 - ExtraTF \n",
      "std_p: 0.96, corr: 0.93, rmse: 0.39, mae_v: 0.28,sm: 45.38 - RandomRF \n",
      "std_p: 0.60, corr: 0.90, rmse: 0.59, mae_v: 0.45,sm: 70.57 - SVR \n",
      "std_p: 0.97, corr: 0.95, rmse: 0.32, mae_v: 0.26,sm: 46.02 - LSTM \n",
      "std_p: 1.07, corr: 0.93, rmse: 0.41, mae_v: 0.33,sm: 59.48 - WBBLSTM \n",
      "✔️ Done with 40712 | 12\n",
      "\n",
      "\n",
      "=== Station 40712 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40712/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40712/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40712/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40712/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40712/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s]\n",
      "std_p: 0.38, corr: 0.28, rmse: 1.04, mae_v: 0.82,sm: 126.98 - ExtraTF \n",
      "std_p: 0.81, corr: 0.96, rmse: 0.33, mae_v: 0.25,sm: 43.19 - RandomRF \n",
      "std_p: 0.63, corr: 0.84, rmse: 0.62, mae_v: 0.48,sm: 84.47 - SVR \n",
      "std_p: 1.03, corr: 0.98, rmse: 0.20, mae_v: 0.16,sm: 45.74 - LSTM \n",
      "std_p: 1.04, corr: 0.98, rmse: 0.22, mae_v: 0.17,sm: 52.12 - WBBLSTM \n",
      "✔️ Done with 40712 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40713 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40713/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40713/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40713/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40713/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40713/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "std_p: 0.42, corr: 0.69, rmse: 0.41, mae_v: 0.31,sm: 95.26 - ExtraTF \n",
      "std_p: 0.39, corr: 0.73, rmse: 0.38, mae_v: 0.29,sm: 85.18 - RandomRF \n",
      "std_p: 0.39, corr: 0.71, rmse: 0.39, mae_v: 0.30,sm: 85.28 - SVR \n",
      "std_p: 0.65, corr: 0.68, rmse: 0.49, mae_v: 0.39,sm: 94.97 - LSTM \n",
      "std_p: 0.29, corr: 0.19, rmse: 0.59, mae_v: 0.47,sm: 136.42 - WBBLSTM \n",
      "✔️ Done with 40713 | 1\n",
      "\n",
      "\n",
      "=== Station 40713 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40713/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40713/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40713/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40713/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40713/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s]\n",
      "std_p: 0.38, corr: 0.54, rmse: 0.46, mae_v: 0.36,sm: 112.86 - ExtraTF \n",
      "std_p: 0.31, corr: 0.56, rmse: 0.44, mae_v: 0.32,sm: 102.81 - RandomRF \n",
      "std_p: 0.20, corr: 0.56, rmse: 0.45, mae_v: 0.31,sm: 112.65 - SVR \n",
      "std_p: 0.50, corr: 0.73, rmse: 0.38, mae_v: 0.26,sm: 87.89 - LSTM \n",
      "std_p: 0.28, corr: 0.48, rmse: 0.47, mae_v: 0.32,sm: 109.99 - WBBLSTM \n",
      "✔️ Done with 40713 | 3\n",
      "\n",
      "\n",
      "=== Station 40713 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40713/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40713/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40713/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40713/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40713/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s]\n",
      "std_p: 0.46, corr: 0.64, rmse: 0.57, mae_v: 0.43,sm: 103.90 - ExtraTF \n",
      "std_p: 0.43, corr: 0.80, rmse: 0.39, mae_v: 0.29,sm: 77.72 - RandomRF \n",
      "std_p: 0.33, corr: 0.72, rmse: 0.48, mae_v: 0.35,sm: 97.74 - SVR \n",
      "std_p: 0.64, corr: 0.90, rmse: 0.28, mae_v: 0.22,sm: 62.57 - LSTM \n",
      "std_p: 0.51, corr: 0.72, rmse: 0.45, mae_v: 0.34,sm: 88.09 - WBBLSTM \n",
      "✔️ Done with 40713 | 6\n",
      "\n",
      "\n",
      "=== Station 40713 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40713/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40713/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40713/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40713/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40713/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.50it/s]\n",
      "std_p: 0.65, corr: 0.82, rmse: 0.47, mae_v: 0.37,sm: 72.27 - ExtraTF \n",
      "std_p: 0.61, corr: 0.88, rmse: 0.36, mae_v: 0.27,sm: 62.01 - RandomRF \n",
      "std_p: 0.44, corr: 0.82, rmse: 0.47, mae_v: 0.37,sm: 82.76 - SVR \n",
      "std_p: 0.75, corr: 0.91, rmse: 0.32, mae_v: 0.25,sm: 55.09 - LSTM \n",
      "std_p: 0.74, corr: 0.80, rmse: 0.47, mae_v: 0.35,sm: 74.29 - WBBLSTM \n",
      "✔️ Done with 40713 | 9\n",
      "\n",
      "\n",
      "=== Station 40713 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40713/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40713/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40713/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40713/12\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40713/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s]\n",
      "std_p: 0.54, corr: 0.16, rmse: 0.93, mae_v: 0.82,sm: 148.48 - ExtraTF \n",
      "std_p: 0.69, corr: 0.91, rmse: 0.36, mae_v: 0.29,sm: 55.46 - RandomRF \n",
      "std_p: 0.53, corr: 0.86, rmse: 0.46, mae_v: 0.37,sm: 77.39 - SVR \n",
      "std_p: 0.76, corr: 0.95, rmse: 0.25, mae_v: 0.20,sm: 39.02 - LSTM \n",
      "std_p: 0.75, corr: 0.86, rmse: 0.42, mae_v: 0.34,sm: 63.94 - WBBLSTM \n",
      "✔️ Done with 40713 | 12\n",
      "\n",
      "\n",
      "=== Station 40713 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40713/24\\ExtraTF…\n",
      "negative corr\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40713/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40713/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40713/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40713/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s]\n",
      "std_p: 0.78, corr: 0.46, rmse: 1.10, mae_v: 0.88,sm: 120.97 - ExtraTF \n",
      "std_p: 0.71, corr: 0.94, rmse: 0.27, mae_v: 0.23,sm: 40.15 - RandomRF \n",
      "std_p: 0.56, corr: 0.90, rmse: 0.37, mae_v: 0.29,sm: 58.16 - SVR \n",
      "std_p: 0.77, corr: 0.96, rmse: 0.23, mae_v: 0.17,sm: 35.73 - LSTM \n",
      "std_p: 0.74, corr: 0.95, rmse: 0.23, mae_v: 0.19,sm: 34.78 - WBBLSTM \n",
      "✔️ Done with 40713 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40716 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40716/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40716/1\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40716/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40716/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40716/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "std_p: 0.56, corr: 0.73, rmse: 0.46, mae_v: 0.35,sm: 91.53 - ExtraTF \n",
      "std_p: 0.49, corr: 0.75, rmse: 0.43, mae_v: 0.31,sm: 83.56 - RandomRF \n",
      "std_p: 0.51, corr: 0.77, rmse: 0.42, mae_v: 0.31,sm: 83.14 - SVR \n",
      "std_p: 0.63, corr: 0.74, rmse: 0.47, mae_v: 0.35,sm: 92.00 - LSTM \n",
      "std_p: 0.31, corr: 0.13, rmse: 0.72, mae_v: 0.58,sm: 150.89 - WBBLSTM \n",
      "✔️ Done with 40716 | 1\n",
      "\n",
      "\n",
      "=== Station 40716 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40716/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40716/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40716/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40716/3\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40716/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
      "std_p: 0.46, corr: 0.64, rmse: 0.46, mae_v: 0.37,sm: 95.79 - ExtraTF \n",
      "std_p: 0.36, corr: 0.74, rmse: 0.41, mae_v: 0.31,sm: 95.81 - RandomRF \n",
      "std_p: 0.27, corr: 0.66, rmse: 0.49, mae_v: 0.39,sm: 119.22 - SVR \n",
      "std_p: 0.62, corr: 0.73, rmse: 0.46, mae_v: 0.34,sm: 89.25 - LSTM \n",
      "std_p: 0.38, corr: 0.66, rmse: 0.46, mae_v: 0.35,sm: 101.76 - WBBLSTM \n",
      "✔️ Done with 40716 | 3\n",
      "\n",
      "\n",
      "=== Station 40716 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40716/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40716/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40716/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40716/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40716/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s]\n",
      "std_p: 0.65, corr: 0.27, rmse: 0.84, mae_v: 0.61,sm: 107.56 - ExtraTF \n",
      "std_p: 0.47, corr: 0.80, rmse: 0.45, mae_v: 0.32,sm: 80.95 - RandomRF \n",
      "std_p: 0.36, corr: 0.77, rmse: 0.53, mae_v: 0.39,sm: 103.13 - SVR \n",
      "std_p: 0.60, corr: 0.85, rmse: 0.40, mae_v: 0.28,sm: 71.86 - LSTM \n",
      "std_p: 0.55, corr: 0.74, rmse: 0.52, mae_v: 0.38,sm: 88.21 - WBBLSTM \n",
      "✔️ Done with 40716 | 6\n",
      "\n",
      "\n",
      "=== Station 40716 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40716/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40716/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40716/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40716/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40716/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n",
      "std_p: 0.64, corr: 0.37, rmse: 0.85, mae_v: 0.73,sm: 126.12 - ExtraTF \n",
      "std_p: 0.64, corr: 0.90, rmse: 0.39, mae_v: 0.32,sm: 59.53 - RandomRF \n",
      "std_p: 0.43, corr: 0.84, rmse: 0.56, mae_v: 0.47,sm: 100.13 - SVR \n",
      "std_p: 0.76, corr: 0.90, rmse: 0.41, mae_v: 0.33,sm: 66.68 - LSTM \n",
      "std_p: 0.72, corr: 0.78, rmse: 0.57, mae_v: 0.45,sm: 86.56 - WBBLSTM \n",
      "✔️ Done with 40716 | 9\n",
      "\n",
      "\n",
      "=== Station 40716 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40716/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40716/12\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40716/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40716/12\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40716/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n",
      "std_p: 0.79, corr: 0.05, rmse: 1.22, mae_v: 1.06,sm: 134.66 - ExtraTF \n",
      "std_p: 0.72, corr: 0.87, rmse: 0.49, mae_v: 0.36,sm: 63.35 - RandomRF \n",
      "std_p: 0.56, corr: 0.87, rmse: 0.59, mae_v: 0.45,sm: 73.45 - SVR \n",
      "std_p: 0.81, corr: 0.92, rmse: 0.40, mae_v: 0.29,sm: 41.79 - LSTM \n",
      "std_p: 0.80, corr: 0.92, rmse: 0.45, mae_v: 0.35,sm: 51.76 - WBBLSTM \n",
      "✔️ Done with 40716 | 12\n",
      "\n",
      "\n",
      "=== Station 40716 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40716/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40716/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40716/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40716/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40716/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s]\n",
      "std_p: 0.44, corr: 0.71, rmse: 0.86, mae_v: 0.76,sm: 111.04 - ExtraTF \n",
      "std_p: 0.89, corr: 0.95, rmse: 0.37, mae_v: 0.30,sm: 46.48 - RandomRF \n",
      "std_p: 0.73, corr: 0.92, rmse: 0.55, mae_v: 0.43,sm: 69.09 - SVR \n",
      "std_p: 0.98, corr: 0.97, rmse: 0.32, mae_v: 0.23,sm: 39.57 - LSTM \n",
      "std_p: 1.06, corr: 0.94, rmse: 0.37, mae_v: 0.28,sm: 44.83 - WBBLSTM \n",
      "✔️ Done with 40716 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40717 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40717/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40717/1\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40717/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40717/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40717/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s]\n",
      "std_p: 0.56, corr: 0.68, rmse: 0.53, mae_v: 0.40,sm: 108.03 - ExtraTF \n",
      "std_p: 0.49, corr: 0.73, rmse: 0.48, mae_v: 0.34,sm: 98.08 - RandomRF \n",
      "std_p: 0.52, corr: 0.72, rmse: 0.49, mae_v: 0.37,sm: 98.85 - SVR \n",
      "std_p: 0.73, corr: 0.64, rmse: 0.61, mae_v: 0.48,sm: 106.66 - LSTM \n",
      "std_p: 0.24, corr: 0.24, rmse: 0.68, mae_v: 0.52,sm: 136.75 - WBBLSTM \n",
      "✔️ Done with 40717 | 1\n",
      "\n",
      "\n",
      "=== Station 40717 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40717/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40717/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40717/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40717/3\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40717/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s]\n",
      "std_p: 0.56, corr: 0.53, rmse: 0.58, mae_v: 0.44,sm: 106.16 - ExtraTF \n",
      "std_p: 0.38, corr: 0.70, rmse: 0.48, mae_v: 0.35,sm: 93.96 - RandomRF \n",
      "std_p: 0.28, corr: 0.62, rmse: 0.52, mae_v: 0.38,sm: 110.66 - SVR \n",
      "std_p: 0.62, corr: 0.74, rmse: 0.47, mae_v: 0.34,sm: 91.01 - LSTM \n",
      "std_p: 0.52, corr: 0.58, rmse: 0.55, mae_v: 0.43,sm: 110.85 - WBBLSTM \n",
      "✔️ Done with 40717 | 3\n",
      "\n",
      "\n",
      "=== Station 40717 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40717/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40717/6\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40717/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40717/6\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40717/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
      "std_p: 0.60, corr: 0.36, rmse: 0.83, mae_v: 0.64,sm: 123.56 - ExtraTF \n",
      "std_p: 0.57, corr: 0.84, rmse: 0.47, mae_v: 0.33,sm: 82.10 - RandomRF \n",
      "std_p: 0.28, corr: 0.82, rmse: 0.62, mae_v: 0.48,sm: 113.47 - SVR \n",
      "std_p: 0.70, corr: 0.83, rmse: 0.46, mae_v: 0.34,sm: 78.80 - LSTM \n",
      "std_p: 0.58, corr: 0.80, rmse: 0.51, mae_v: 0.39,sm: 89.43 - WBBLSTM \n",
      "✔️ Done with 40717 | 6\n",
      "\n",
      "\n",
      "=== Station 40717 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40717/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40717/9\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40717/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40717/9\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.26it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40717/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n",
      "std_p: 0.54, corr: 0.70, rmse: 0.70, mae_v: 0.58,sm: 113.92 - ExtraTF \n",
      "std_p: 0.58, corr: 0.84, rmse: 0.55, mae_v: 0.40,sm: 85.39 - RandomRF \n",
      "std_p: 0.35, corr: 0.79, rmse: 0.69, mae_v: 0.54,sm: 119.67 - SVR \n",
      "std_p: 0.77, corr: 0.84, rmse: 0.51, mae_v: 0.39,sm: 75.33 - LSTM \n",
      "std_p: 0.78, corr: 0.79, rmse: 0.57, mae_v: 0.45,sm: 92.10 - WBBLSTM \n",
      "✔️ Done with 40717 | 9\n",
      "\n",
      "\n",
      "=== Station 40717 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40717/12\\ExtraTF…\n",
      "negative corr\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40717/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40717/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40717/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40717/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s]\n",
      "std_p: 0.71, corr: 0.00, rmse: 1.38, mae_v: 1.05,sm: 137.88 - ExtraTF \n",
      "std_p: 0.59, corr: 0.83, rmse: 0.61, mae_v: 0.45,sm: 87.56 - RandomRF \n",
      "std_p: 0.44, corr: 0.69, rmse: 0.75, mae_v: 0.53,sm: 103.56 - SVR \n",
      "std_p: 0.77, corr: 0.87, rmse: 0.50, mae_v: 0.35,sm: 72.13 - LSTM \n",
      "std_p: 0.70, corr: 0.84, rmse: 0.54, mae_v: 0.39,sm: 79.93 - WBBLSTM \n",
      "✔️ Done with 40717 | 12\n",
      "\n",
      "\n",
      "=== Station 40717 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40717/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40717/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40717/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40717/24\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40717/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s]\n",
      "std_p: 0.30, corr: 0.68, rmse: 1.01, mae_v: 0.86,sm: 156.18 - ExtraTF \n",
      "std_p: 0.69, corr: 0.81, rmse: 0.49, mae_v: 0.38,sm: 83.05 - RandomRF \n",
      "std_p: 0.40, corr: 0.71, rmse: 0.61, mae_v: 0.47,sm: 93.38 - SVR \n",
      "std_p: 0.63, corr: 0.87, rmse: 0.41, mae_v: 0.32,sm: 71.66 - LSTM \n",
      "std_p: 0.60, corr: 0.89, rmse: 0.40, mae_v: 0.31,sm: 64.53 - WBBLSTM \n",
      "✔️ Done with 40717 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 40726 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40726/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40726/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40726/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40726/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40726/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.57it/s]\n",
      "std_p: 0.59, corr: 0.52, rmse: 0.76, mae_v: 0.44,sm: 102.75 - ExtraTF \n",
      "std_p: 0.45, corr: 0.71, rmse: 0.64, mae_v: 0.26,sm: 72.03 - RandomRF \n",
      "std_p: 0.41, corr: 0.60, rmse: 0.71, mae_v: 0.28,sm: 68.85 - SVR \n",
      "std_p: 0.71, corr: 0.68, rmse: 0.67, mae_v: 0.39,sm: 86.71 - LSTM \n",
      "std_p: 0.22, corr: 0.26, rmse: 0.85, mae_v: 0.50,sm: 145.13 - WBBLSTM \n",
      "✔️ Done with 40726 | 1\n",
      "\n",
      "\n",
      "=== Station 40726 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40726/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40726/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40726/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40726/3\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40726/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s]\n",
      "std_p: 0.38, corr: 0.50, rmse: 0.63, mae_v: 0.39,sm: 113.33 - ExtraTF \n",
      "std_p: 0.23, corr: 0.55, rmse: 0.63, mae_v: 0.34,sm: 107.41 - RandomRF \n",
      "std_p: 0.17, corr: 0.49, rmse: 0.66, mae_v: 0.37,sm: 136.53 - SVR \n",
      "std_p: 0.48, corr: 0.63, rmse: 0.57, mae_v: 0.34,sm: 91.50 - LSTM \n",
      "std_p: 0.27, corr: 0.52, rmse: 0.63, mae_v: 0.38,sm: 130.65 - WBBLSTM \n",
      "✔️ Done with 40726 | 3\n",
      "\n",
      "\n",
      "=== Station 40726 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40726/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40726/6\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40726/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40726/6\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40726/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s]\n",
      "std_p: 0.32, corr: 0.58, rmse: 0.89, mae_v: 0.60,sm: 126.67 - ExtraTF \n",
      "std_p: 0.33, corr: 0.74, rmse: 0.84, mae_v: 0.46,sm: 98.91 - RandomRF \n",
      "std_p: 0.24, corr: 0.60, rmse: 0.91, mae_v: 0.55,sm: 139.10 - SVR \n",
      "std_p: 0.59, corr: 0.62, rmse: 0.81, mae_v: 0.50,sm: 98.11 - LSTM \n",
      "std_p: 0.59, corr: 0.68, rmse: 0.77, mae_v: 0.52,sm: 111.67 - WBBLSTM \n",
      "✔️ Done with 40726 | 6\n",
      "\n",
      "\n",
      "=== Station 40726 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40726/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40726/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40726/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40726/9\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40726/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "std_p: 0.45, corr: 0.38, rmse: 1.34, mae_v: 1.02,sm: 154.81 - ExtraTF \n",
      "std_p: 0.55, corr: 0.72, rmse: 1.18, mae_v: 0.63,sm: 91.89 - RandomRF \n",
      "std_p: 0.41, corr: 0.63, rmse: 1.26, mae_v: 0.78,sm: 133.81 - SVR \n",
      "std_p: 0.69, corr: 0.83, rmse: 0.98, mae_v: 0.58,sm: 91.99 - LSTM \n",
      "std_p: 0.86, corr: 0.73, rmse: 1.01, mae_v: 0.62,sm: 99.39 - WBBLSTM \n",
      "✔️ Done with 40726 | 9\n",
      "\n",
      "\n",
      "=== Station 40726 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40726/12\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40726/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40726/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40726/12\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.18it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40726/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s]\n",
      "std_p: 0.55, corr: 0.74, rmse: 1.58, mae_v: 1.06,sm: 122.86 - ExtraTF \n",
      "std_p: 0.67, corr: 0.74, rmse: 1.37, mae_v: 0.79,sm: 89.25 - RandomRF \n",
      "std_p: 0.53, corr: 0.67, rmse: 1.39, mae_v: 0.90,sm: 134.47 - SVR \n",
      "std_p: 1.02, corr: 0.84, rmse: 0.98, mae_v: 0.55,sm: 65.99 - LSTM \n",
      "std_p: 1.02, corr: 0.82, rmse: 1.02, mae_v: 0.62,sm: 79.09 - WBBLSTM \n",
      "✔️ Done with 40726 | 12\n",
      "\n",
      "\n",
      "=== Station 40726 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\40726/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\40726/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\40726/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\40726/24\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.67it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\40726/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s]\n",
      "std_p: 0.20, corr: 0.19, rmse: 2.00, mae_v: 1.46,sm: 144.34 - ExtraTF \n",
      "std_p: 0.64, corr: 0.80, rmse: 1.20, mae_v: 0.79,sm: 67.74 - RandomRF \n",
      "std_p: 0.59, corr: 0.72, rmse: 1.28, mae_v: 0.96,sm: 125.88 - SVR \n",
      "std_p: 0.94, corr: 0.88, rmse: 0.82, mae_v: 0.53,sm: 51.81 - LSTM \n",
      "std_p: 1.13, corr: 0.86, rmse: 0.76, mae_v: 0.42,sm: 39.78 - WBBLSTM \n",
      "✔️ Done with 40726 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n",
      "\n",
      "=== Station 88107 | 1 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\88107/1\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\88107/1\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\88107/1\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\88107/1\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\88107/1\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s]\n",
      "std_p: 0.67, corr: 0.70, rmse: 0.58, mae_v: 0.45,sm: 99.43 - ExtraTF \n",
      "std_p: 0.57, corr: 0.72, rmse: 0.54, mae_v: 0.46,sm: 117.98 - RandomRF \n",
      "std_p: 0.61, corr: 0.75, rmse: 0.52, mae_v: 0.41,sm: 95.45 - SVR \n",
      "std_p: 0.80, corr: 0.77, rmse: 0.54, mae_v: 0.44,sm: 103.31 - LSTM \n",
      "std_p: 0.32, corr: 0.40, rmse: 0.72, mae_v: 0.60,sm: 147.52 - WBBLSTM \n",
      "✔️ Done with 88107 | 1\n",
      "\n",
      "\n",
      "=== Station 88107 | 3 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\88107/3\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\88107/3\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\88107/3\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\88107/3\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\88107/3\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "std_p: 0.37, corr: 0.66, rmse: 0.56, mae_v: 0.47,sm: 120.23 - ExtraTF \n",
      "std_p: 0.36, corr: 0.87, rmse: 0.46, mae_v: 0.37,sm: 95.02 - RandomRF \n",
      "std_p: 0.42, corr: 0.69, rmse: 0.54, mae_v: 0.42,sm: 105.87 - SVR \n",
      "std_p: 0.71, corr: 0.72, rmse: 0.55, mae_v: 0.46,sm: 108.48 - LSTM \n",
      "std_p: 0.36, corr: 0.28, rmse: 0.72, mae_v: 0.57,sm: 137.73 - WBBLSTM \n",
      "✔️ Done with 88107 | 3\n",
      "\n",
      "\n",
      "=== Station 88107 | 6 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\88107/6\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\88107/6\\RandomRF…\n",
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\88107/6\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\88107/6\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\88107/6\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s]\n",
      "std_p: 0.20, corr: 0.14, rmse: 0.93, mae_v: 0.80,sm: 153.75 - ExtraTF \n",
      "std_p: 0.62, corr: 0.87, rmse: 0.51, mae_v: 0.41,sm: 77.81 - RandomRF \n",
      "std_p: 0.41, corr: 0.78, rmse: 0.67, mae_v: 0.58,sm: 110.20 - SVR \n",
      "std_p: 0.82, corr: 0.92, rmse: 0.37, mae_v: 0.29,sm: 56.66 - LSTM \n",
      "std_p: 0.79, corr: 0.79, rmse: 0.58, mae_v: 0.45,sm: 80.31 - WBBLSTM \n",
      "✔️ Done with 88107 | 6\n",
      "\n",
      "\n",
      "=== Station 88107 | 9 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\88107/9\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\88107/9\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\88107/9\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\88107/9\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\88107/9\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s]\n",
      "std_p: 0.51, corr: 0.84, rmse: 0.79, mae_v: 0.70,sm: 144.83 - ExtraTF \n",
      "std_p: 0.58, corr: 0.80, rmse: 0.62, mae_v: 0.53,sm: 104.13 - RandomRF \n",
      "std_p: 0.40, corr: 0.73, rmse: 0.73, mae_v: 0.64,sm: 131.62 - SVR \n",
      "std_p: 0.96, corr: 0.86, rmse: 0.53, mae_v: 0.43,sm: 84.27 - LSTM \n",
      "std_p: 0.80, corr: 0.75, rmse: 0.65, mae_v: 0.52,sm: 99.51 - WBBLSTM \n",
      "✔️ Done with 88107 | 9\n",
      "\n",
      "\n",
      "=== Station 88107 | 12 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\88107/12\\ExtraTF…\n",
      "negative corr\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\88107/12\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\88107/12\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\88107/12\\LSTM…\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s]\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\88107/12\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.71it/s]\n",
      "std_p: 0.33, corr: 0.01, rmse: 1.20, mae_v: 1.05,sm: 175.77 - ExtraTF \n",
      "std_p: 0.60, corr: 0.83, rmse: 0.58, mae_v: 0.48,sm: 101.98 - RandomRF \n",
      "std_p: 0.41, corr: 0.69, rmse: 0.75, mae_v: 0.66,sm: 136.29 - SVR \n",
      "std_p: 0.93, corr: 0.85, rmse: 0.53, mae_v: 0.45,sm: 98.85 - LSTM \n",
      "std_p: 0.87, corr: 0.74, rmse: 0.80, mae_v: 0.68,sm: 121.55 - WBBLSTM \n",
      "✔️ Done with 88107 | 12\n",
      "\n",
      "\n",
      "=== Station 88107 | 24 ===\n",
      "Model ExtraTF already trained. Skipping.\n",
      "!!!@@@-----Loading ExtraTF model from results\\88107/24\\ExtraTF…\n",
      "Model RandomRF already trained. Skipping.\n",
      "!!!@@@-----Loading RandomRF model from results\\88107/24\\RandomRF…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVR already trained. Skipping.\n",
      "!!!@@@-----Loading SVR model from results\\88107/24\\SVR…\n",
      "Model LSTM already trained. Skipping.\n",
      "!!!@@@-----Loading LSTM model from results\\88107/24\\LSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model WBBLSTM already trained. Skipping.\n",
      "!!!@@@-----Loading WBBLSTM model from results\\88107/24\\WBBLSTM…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s]\n",
      "std_p: 1.01, corr: 0.78, rmse: 1.10, mae_v: 0.91,sm: 125.32 - ExtraTF \n",
      "std_p: 0.72, corr: 0.84, rmse: 0.54, mae_v: 0.46,sm: 85.16 - RandomRF \n",
      "std_p: 0.43, corr: 0.77, rmse: 0.70, mae_v: 0.61,sm: 118.97 - SVR \n",
      "std_p: 0.86, corr: 0.83, rmse: 0.58, mae_v: 0.45,sm: 97.24 - LSTM \n",
      "std_p: 0.73, corr: 0.64, rmse: 0.76, mae_v: 0.63,sm: 119.18 - WBBLSTM \n",
      "✔️ Done with 88107 | 24\n",
      "\n",
      "📄 Results saved as CSV: results\\results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "results = {}  \n",
    "base_dir = \"results\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "df = load_data('./finaldata.csv')\n",
    "stations = df['station'].unique()\n",
    "summary = []\n",
    "\n",
    "def model_score(stats):\n",
    "    std_o, std_p, corr, rmse, mape_val, _ = stats\n",
    "    std_diff = abs(std_o - std_p)\n",
    "    return (\n",
    "        rmse + mape_val + std_diff - corr  \n",
    "    )\n",
    "\n",
    "plot_start = pd.Timestamp(\"2017-01-01\")\n",
    "plot_end   = pd.Timestamp(\"2024-04-01\")\n",
    "\n",
    "for st in stations:\n",
    "# for st in [40701]:\n",
    "    df_st = df[df['station'] == st].copy()\n",
    "    for ts in [1,3,6,9,12,24]:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        results[st] = {}\n",
    "        data = make_features(df_st, ts)\n",
    "        print(f\"\\n=== Station {st} | {ts} ===\")\n",
    "        target_series = TimeSeries.from_series(data[\"spi_deseason\"])\n",
    "        target_series = target_series.astype(np.float32)  \n",
    "\n",
    "        covariates = TimeSeries.from_dataframe(\n",
    "            data[[\"rainfall\"] + [f\"spi_lag_{i}\" for i in range(1, 13)]]\n",
    "        )\n",
    "        covariates = covariates.astype(np.float32)\n",
    "        target_series, covariates = target_series.slice_intersect(covariates), covariates.slice_intersect(target_series)\n",
    "\n",
    "        train, val = target_series.split_before(0.8)\n",
    "        target_series.slice(plot_start, plot_end).plot(label=\"Observed\", lw=2)\n",
    "\n",
    "        model_folder = os.path.join(base_dir, f\"{st}/{ts}\")\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "        model_stats = {}\n",
    "        forecasts = {}\n",
    "        for name, mk in model_constructors.items():\n",
    "            model_path = os.path.join(model_folder, name)\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"Model {name} already trained. Skipping.\")\n",
    "                model_class = {\n",
    "                    'LSTM': RNNModel,\n",
    "                    'SVR': RegressionModel,\n",
    "                    'RandomRF': RandomForest,\n",
    "                    'ExtraTF': XGBModel,\n",
    "                    'WBBLSTM': WBBLSTMModel\n",
    "                }[name]\n",
    "                print(f\"!!!@@@-----Loading {name} model from {model_path}…\")\n",
    "                model = model_class.load(model_path)\n",
    "\n",
    "            else:\n",
    "                print(f\"!!!@@@------Training {name}…\", end='')\n",
    "                model = mk()\n",
    "                model.fit(series=train, future_covariates=covariates)\n",
    "                model.save(model_path)\n",
    "\n",
    "                print(\" saved.\")\n",
    "\n",
    "            forecast = model.predict(len(val), series=train, future_covariates=covariates)\n",
    "            forecast_zoom = forecast.slice(plot_start, plot_end)\n",
    "            forecast_zoom.plot(label=name, lw=1.8)\n",
    "            o = val.values().flatten()\n",
    "            p = forecast.values().flatten()\n",
    "\n",
    "            corr = pearsonr(o, p)[0]\n",
    "            if corr < 0:\n",
    "                print('negative corr')\n",
    "                p = -p\n",
    "                corr = -corr\n",
    "\n",
    "\n",
    "            rm   = np.sqrt(mean_squared_error(o, p))\n",
    "            mae_v= mean_absolute_error(o, p)\n",
    "            sm   = np.mean(2 * np.abs(o-p) / (np.abs(o)+np.abs(p))) * 100\n",
    "\n",
    "            model_stats[name] = (np.std(o), np.std(p), corr, rm, mae_v, sm)\n",
    "            \n",
    "            forecasts[name] = forecast\n",
    "\n",
    "\n",
    "        plt.title(f\"Model Comparison — Station {st} | Timescale: SPI-{ts}\", fontsize=14)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"SPI Value\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(model_folder, f\"all_models_{st}_{ts}.png\"), dpi=300)\n",
    "        plt.close()\n",
    "        results[st][f\"spi_{ts}\"] = model_stats\n",
    "        for model_name, stats in model_stats.items():\n",
    "                        std_o, std_p, corr, rmse, mae, smape = stats\n",
    "                        score = model_score(stats)\n",
    "                        summary.append({\n",
    "                            'Station': st,\n",
    "                            'Timescale': ts,\n",
    "                            'Model': model_name,\n",
    "                            'STD_Obs': std_o,\n",
    "                            'STD_Pred': std_p,\n",
    "                            'Corr': corr,\n",
    "                            'RMSE': rmse,\n",
    "                            'MAE': mae,\n",
    "                            'SMAPE': smape,\n",
    "                            'Score': score,\n",
    "                        })\n",
    "\n",
    "        # Taylor Diagram\n",
    "        ref_std = list(model_stats.values())[0][0]\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        taylor = TaylorDiagram(ref_std, fig, label='Observed')\n",
    "        for name, (std_o, std_p, corr, rmse,mae_v,sm) in model_stats.items():\n",
    "            print(f\"std_p: {std_p:.2f}, corr: {corr:.2f}, rmse: {rmse:.2f}, mae_v: {mae_v:.2f},sm: {sm:.2f} - {name} \")\n",
    "            if np.isnan(std_p) or np.isnan(corr) or std_p == 0:\n",
    "                print(f\"⚠️ Skipping {name} due to invalid metrics.\")\n",
    "                continue\n",
    "            taylor.add_sample(std_p, corr, label=name)\n",
    "        taylor.add_contours()\n",
    "        plt.legend()\n",
    "        plt.title(f\"Taylor Diagram: Station {st} | {ts}\")\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(os.path.join(model_folder, f\"taylor_{st}_{ts}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Best model\n",
    "        best_model = min(model_stats.items(), key=lambda x: model_score(x[1]))[0]\n",
    "#         best_model = min(\n",
    "#     model_stats.items(),\n",
    "#     key=lambda item: (item[1][3], -item[1][2])\n",
    "# )[0]\n",
    "\n",
    "        # Plot val vs pred\n",
    "        _, val = target_series.split_before(0.8)\n",
    "        time_idx = val.time_index\n",
    "        pred = forecasts[best_model]\n",
    "        val_df  = val.to_dataframe()  \n",
    "        pred_df = pred.to_dataframe()\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        val.plot(label=\"Observed\")\n",
    "        pred.plot(label=f\"Forecast - {best_model}\")\n",
    "        plt.title(f\"Validation vs Prediction — {st} | {ts}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(model_folder, f\"val_vs_pred_{st}_{ts}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"✔️ Done with {st} | {ts}\\n\")\n",
    "    df_summary = pd.DataFrame(summary)\n",
    "    # Identify best model (custom score and RMSE)\n",
    "    df_summary['Best_Model'] = df_summary.groupby(['Station', 'Timescale'])['Score'].transform(\n",
    "        lambda x: x == x.min()\n",
    "    )\n",
    "    # df_summary['Best_RMSE'] = df_summary.groupby(['Station', 'Timescale'])['RMSE'].transform(\n",
    "    #     lambda x: x == x.min()\n",
    "    # )\n",
    "    df_summary['Winner'] = df_summary.apply(\n",
    "    lambda row: '✔' if row['Best_Model'] else '', axis=1\n",
    ")\n",
    "\n",
    "    # Drop helper columns\n",
    "    df_summary.drop(columns=['Best_Model'], inplace=True)\n",
    "\n",
    "    # Round all float columns to 2 decimal places\n",
    "    float_cols = df_summary.select_dtypes(include='float').columns\n",
    "    df_summary[float_cols] = df_summary[float_cols].round(2)\n",
    "\n",
    "\n",
    "    # Replace repeated values with empty string to simulate merged cells\n",
    "    df_summary[['Station', 'Timescale']] = (\n",
    "        df_summary.groupby(['Station', 'Timescale'])[['Station', 'Timescale']]\n",
    "        .transform(lambda x: [x.iloc[0]] + [''] * (len(x) - 1))\n",
    "    )\n",
    "\n",
    "    # Save CSV\n",
    "    df_summary_path = os.path.join(base_dir, 'results_summary.csv')\n",
    "    df_summary.to_csv(df_summary_path, index=False)\n",
    "    print(f\"📄 Results saved as CSV: {df_summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "435d6aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " • Forecast + CSV saved for SPI-1 (ExtraTF)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 4.9 K  | train\n",
      "6 | V               | Linear           | 33     | train\n",
      "-------------------------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 24/24 [00:00<00:00, 53.09it/s, train_loss=0.0687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 24/24 [00:00<00:00, 52.40it/s, train_loss=0.0687]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 4.9 K  | train\n",
      "6 | V               | Linear           | 33     | train\n",
      "-------------------------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " • Forecast + CSV saved for SPI-3 (LSTM)\n",
      "Epoch 149: 100%|██████████| 24/24 [00:00<00:00, 60.60it/s, train_loss=0.0518] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 24/24 [00:00<00:00, 60.13it/s, train_loss=0.0518]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 4.9 K  | train\n",
      "6 | V               | Linear           | 33     | train\n",
      "-------------------------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " • Forecast + CSV saved for SPI-6 (LSTM)\n",
      "Epoch 149: 100%|██████████| 23/23 [00:00<00:00, 55.95it/s, train_loss=0.0667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 23/23 [00:00<00:00, 55.41it/s, train_loss=0.0667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 4.9 K  | train\n",
      "6 | V               | Linear           | 33     | train\n",
      "-------------------------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " • Forecast + CSV saved for SPI-9 (LSTM)\n",
      "Epoch 149: 100%|██████████| 23/23 [00:00<00:00, 44.01it/s, train_loss=0.0541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 23/23 [00:00<00:00, 43.68it/s, train_loss=0.0541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ignoring user defined `output_chunk_length`. RNNModel uses a fixed `output_chunk_length=1`.\n",
      "c:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 4.9 K  | train\n",
      "6 | V               | Linear           | 33     | train\n",
      "-------------------------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " • Forecast + CSV saved for SPI-12 (LSTM)\n",
      "Epoch 149: 100%|██████████| 23/23 [00:00<00:00, 55.73it/s, train_loss=0.0349]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 23/23 [00:00<00:00, 55.33it/s, train_loss=0.0349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      " • Forecast + CSV saved for SPI-24 (LSTM)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m train_cov \u001b[38;5;241m=\u001b[39m train_cov_full\u001b[38;5;241m.\u001b[39mslice_intersect(target)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Fit model on full history with enriched covariates\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_cov\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_path)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Build future covariates (same structure)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\regression_model.py:943\u001b[0m, in \u001b[0;36mRegressionModel.fit\u001b[1;34m(self, series, past_covariates, future_covariates, max_samples_per_ts, n_jobs_multioutput_wrapper, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(component_lags_error_msg) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    941\u001b[0m     raise_log(\u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(component_lags_error_msg)), logger)\n\u001b[1;32m--> 943\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_model(\n\u001b[0;32m    944\u001b[0m     series\u001b[38;5;241m=\u001b[39mseries,\n\u001b[0;32m    945\u001b[0m     past_covariates\u001b[38;5;241m=\u001b[39mpast_covariates,\n\u001b[0;32m    946\u001b[0m     future_covariates\u001b[38;5;241m=\u001b[39mfuture_covariates,\n\u001b[0;32m    947\u001b[0m     val_series\u001b[38;5;241m=\u001b[39mval_series,\n\u001b[0;32m    948\u001b[0m     val_past_covariates\u001b[38;5;241m=\u001b[39mval_past_covariates,\n\u001b[0;32m    949\u001b[0m     val_future_covariates\u001b[38;5;241m=\u001b[39mval_future_covariates,\n\u001b[0;32m    950\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    951\u001b[0m     val_sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[0;32m    952\u001b[0m     max_samples_per_ts\u001b[38;5;241m=\u001b[39mmax_samples_per_ts,\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    954\u001b[0m )\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\regression_model.py:702\u001b[0m, in \u001b[0;36mRegressionModel._fit_model\u001b[1;34m(self, series, past_covariates, future_covariates, max_samples_per_ts, sample_weight, val_series, val_past_covariates, val_future_covariates, val_sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit_model\u001b[39m(\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    687\u001b[0m     series: Sequence[TimeSeries],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    697\u001b[0m ):\n\u001b[0;32m    698\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;124;03m    Function that fit the model. Deriving classes can override this method for adding additional\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03m    parameters (e.g., adding validation data), keeping the sanity checks on series performed by fit().\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m     training_samples, training_labels, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_lagged_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_static_covariates_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_val_set \u001b[38;5;129;01mand\u001b[39;00m val_series \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    712\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_val_set_to_kwargs(\n\u001b[0;32m    713\u001b[0m             kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    714\u001b[0m             val_series\u001b[38;5;241m=\u001b[39mval_series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    718\u001b[0m             max_samples_per_ts\u001b[38;5;241m=\u001b[39mmax_samples_per_ts,\n\u001b[0;32m    719\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\models\\forecasting\\regression_model.py:625\u001b[0m, in \u001b[0;36mRegressionModel._create_lagged_data\u001b[1;34m(self, series, past_covariates, future_covariates, max_samples_per_ts, sample_weight, last_static_covariates_shape)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_lagged_data\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    612\u001b[0m     series: Sequence[TimeSeries],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    617\u001b[0m     last_static_covariates_shape: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    618\u001b[0m ):\n\u001b[0;32m    619\u001b[0m     (\n\u001b[0;32m    620\u001b[0m         features,\n\u001b[0;32m    621\u001b[0m         labels,\n\u001b[0;32m    622\u001b[0m         _,\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_static_covariates_shape,\n\u001b[0;32m    624\u001b[0m         sample_weights,\n\u001b[1;32m--> 625\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_lagged_training_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_past_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_future_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfuture\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43muses_static_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muses_static_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_static_covariates_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_static_covariates_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m     expected_nb_feat \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    644\u001b[0m         features[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    645\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, Sequence)\n\u001b[0;32m    646\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    647\u001b[0m     )\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (X_i, y_i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(features, labels)):\n\u001b[0;32m    649\u001b[0m         \u001b[38;5;66;03m# TODO: account for scenario where two wrong shapes can silently hide the problem\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\utils\\data\\tabularization.py:545\u001b[0m, in \u001b[0;36mcreate_lagged_training_data\u001b[1;34m(target_series, output_chunk_length, output_chunk_shift, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, uses_static_covariates, last_static_covariates_shape, max_samples_per_ts, multi_models, check_inputs, use_moving_windows, concatenate, sample_weight)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_lagged_training_data\u001b[39m(\n\u001b[0;32m    406\u001b[0m     target_series: Union[TimeSeries, Sequence[TimeSeries]],\n\u001b[0;32m    407\u001b[0m     output_chunk_length: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    427\u001b[0m     Optional[ArrayOrArraySequence],\n\u001b[0;32m    428\u001b[0m ]:\n\u001b[0;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03m    Creates the features array `X` and labels array `y` to train a lagged-variables regression model (e.g. an\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    `sklearn` model); the time index values of each observation is also returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m        pd.RangeIndex, but `future_covariates` uses a `pd.DatetimeIndex`).\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_lagged_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_past_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags_past_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_future_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags_future_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43muses_static_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muses_static_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_static_covariates_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_static_covariates_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_moving_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_moving_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\utils\\data\\tabularization.py:344\u001b[0m, in \u001b[0;36mcreate_lagged_data\u001b[1;34m(target_series, past_covariates, future_covariates, lags, lags_past_covariates, lags_future_covariates, output_chunk_length, output_chunk_shift, uses_static_covariates, last_static_covariates_shape, max_samples_per_ts, multi_models, check_inputs, use_moving_windows, is_training, concatenate, sample_weight, show_warnings)\u001b[0m\n\u001b[0;32m    335\u001b[0m     raise_log(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot create tabularized data for the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mth series because target and covariates don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m         logger,\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_moving_windows \u001b[38;5;129;01mand\u001b[39;00m series_equal_freq:\n\u001b[1;32m--> 344\u001b[0m     X_i, y_i, times_i, weights_i \u001b[38;5;241m=\u001b[39m \u001b[43m_create_lagged_data_by_moving_window\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_past_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags_past_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_future_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags_future_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_extract\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags_extract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlags_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_warnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     X_i, y_i, times_i, weights_i \u001b[38;5;241m=\u001b[39m _create_lagged_data_by_intersecting_times(\n\u001b[0;32m    364\u001b[0m         target_series\u001b[38;5;241m=\u001b[39mtarget_i,\n\u001b[0;32m    365\u001b[0m         output_chunk_length\u001b[38;5;241m=\u001b[39moutput_chunk_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    377\u001b[0m         show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[0;32m    378\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\utils\\data\\tabularization.py:1101\u001b[0m, in \u001b[0;36m_create_lagged_data_by_moving_window\u001b[1;34m(target_series, output_chunk_length, output_chunk_shift, past_covariates, future_covariates, sample_weight, lags, lags_past_covariates, lags_future_covariates, lags_extract, lags_order, max_samples_per_ts, multi_models, check_inputs, is_training, show_warnings)\u001b[0m\n\u001b[0;32m   1093\u001b[0m windows \u001b[38;5;241m=\u001b[39m strided_moving_window(\n\u001b[0;32m   1094\u001b[0m     x\u001b[38;5;241m=\u001b[39mvals, window_len\u001b[38;5;241m=\u001b[39mwindow_len, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, check_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m )\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# Within each window, the `-1` indexed value (i.e. the value at the very end of\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# the window) corresponds to time `t - min_lag_i`. The negative index of the time\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# `t + lag_i` within this window is, therefore, `-1 + lag_i + min_lag_i`:\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;66;03m# extract lagged values\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m lagged_vals \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_lagged_vals_from_windows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags_extract_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_lag_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;66;03m# extract and append the reordered lagged values\u001b[39;00m\n\u001b[0;32m   1105\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(lagged_vals[:, lags_order_i])\n",
      "File \u001b[1;32mc:\\Users\\varas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\darts\\utils\\data\\tabularization.py:1192\u001b[0m, in \u001b[0;36m_extract_lagged_vals_from_windows\u001b[1;34m(windows, lags_to_extract, lags_shift)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     windows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(windows, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;66;03m# lagged_vals.shape = (num_windows, num_components*window_len, num_samples):\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     lagged_vals \u001b[38;5;241m=\u001b[39m \u001b[43mwindows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lagged_vals\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis,1)"
     ]
    }
   ],
   "source": [
    "def build_future_covariates(covariates: TimeSeries, end_date: str) -> TimeSeries:\n",
    "    df = covariates.to_dataframe()[['rainfall']].copy()\n",
    "    df['month'] = df.index.month\n",
    "    monthly_means = df.groupby('month')['rainfall'].mean()\n",
    "\n",
    "    # extend backward to cover input_chunk_length\n",
    "    start_date = covariates.start_time() - MonthEnd(0) - pd.DateOffset(months=window_size)\n",
    "    future_idx = pd.date_range(start=start_date, end=end_date, freq=\"MS\")\n",
    "\n",
    "    df_future = pd.DataFrame(index=future_idx)\n",
    "    df_future['month'] = df_future.index.month\n",
    "\n",
    "    df_future['rainfall'] = (\n",
    "        df_future['month'].map(monthly_means) +\n",
    "        0.1 * np.sin(2 * np.pi * df_future['month'] / 12) +\n",
    "        np.random.normal(scale=0.1, size=len(df_future))\n",
    "    )\n",
    "    df_future['sin_month'] = np.sin(2 * np.pi * df_future['month'] / 12)\n",
    "    df_future['cos_month'] = np.cos(2 * np.pi * df_future['month'] / 12)\n",
    "\n",
    "    return TimeSeries.from_dataframe(\n",
    "        df_future[['rainfall', 'sin_month', 'cos_month']].astype(np.float32)\n",
    "    )\n",
    "\n",
    "\n",
    "# === Main Forecast Loop ===\n",
    "for st in stations:\n",
    "    for ts in [1,3,6,9,12,24]:\n",
    "        data   = make_features(df[df['station']==st], ts)\n",
    "        target = TimeSeries.from_series(data[\"spi_deseason\"]).astype(np.float32)\n",
    "        raw_cov = TimeSeries.from_dataframe(data[['rainfall']]).astype(np.float32)\n",
    "        target, raw_cov = target.slice_intersect(raw_cov), raw_cov.slice_intersect(target)\n",
    "\n",
    "        # Pick and retrain best model\n",
    "        df_sum = pd.read_csv(os.path.join(base_dir, 'results_summary.csv'))\n",
    "        best   = df_sum.query(\"Station==@st and Timescale==@ts and Best_Model\")['Model'].iloc[0]\n",
    "        model  = model_constructors[best]()\n",
    "        model_folder = os.path.join(base_dir, f\"{st}/{ts}\")\n",
    "\n",
    "        model_path = os.path.join(model_folder, best+\"all\")\n",
    "\n",
    "        # Build enriched training covariates\n",
    "        train_cov_full = build_future_covariates(raw_cov, target.end_time().strftime(\"%Y-%m-%d\"))\n",
    "        train_cov = train_cov_full.slice_intersect(target)\n",
    "\n",
    "        # Fit model on full history with enriched covariates\n",
    "        model.fit(\n",
    "            series=target,\n",
    "            future_covariates=train_cov\n",
    "        )\n",
    "        model.save(model_path)\n",
    "\n",
    "        # Build future covariates (same structure)\n",
    "        forecast_end = \"2058-12-01\"\n",
    "        future_cov = build_future_covariates(raw_cov, forecast_end)\n",
    "        horizon = len(pd.date_range(target.end_time() + MonthEnd(0), forecast_end, freq=\"MS\"))\n",
    "\n",
    "        # Forecast\n",
    "        future_spi = model.predict(\n",
    "            n=horizon,\n",
    "            series=target,\n",
    "            future_covariates=future_cov\n",
    "        )\n",
    "\n",
    "        # Append & save\n",
    "        full = target.append(future_spi)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        full.plot(label=\"SPI\")\n",
    "        plt.axvline(target.end_time(), color='r', ls='--', label=\"Forecast Start\")\n",
    "        plt.title(f\"Station {st} — SPI-{ts} Forecast with {best}\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(base_dir, f\"{st}/{ts}/Forecast_to_2050.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        full.to_dataframe().reset_index().rename(columns={'index': 'date', 0: 'spi_deseason'}) \\\n",
    "            .to_csv(os.path.join(base_dir, f\"{st}/{ts}/SPI_forecast_2050.csv\"), index=False)\n",
    "        print(f\" • Forecast + CSV saved for SPI-{ts} ({best})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489fa27",
   "metadata": {},
   "source": [
    "forecasting with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "\n",
    "#     # best.fit(series=target_series, future_covariates=covariates)\n",
    "        #     best.fit(series=target_series)\n",
    "\n",
    "        \n",
    "\n",
    "        # cov_df = covariates.pd_dataframe()  # or however you get a pandas DataFrame\n",
    "        # cov_df['month'] = cov_df.index.month\n",
    "\n",
    "        # # Compute monthly means for each column except 'month'\n",
    "        # monthly_means = cov_df.groupby('month').mean()\n",
    "\n",
    "        # # 2) Build the future date index from May 2024 to April 2051\n",
    "        # last_hist = covariates.end_time()         # e.g. Timestamp('2024-04-01 00:00:00')\n",
    "        # start_future = last_hist + MonthEnd(1)    # gives end of month, but for MS freq it lines up\n",
    "        # future_idx = pd.date_range(start=start_future,\n",
    "        #                         end=\"2051-04-01\",\n",
    "        #                         freq=\"MS\")\n",
    "\n",
    "        # # 3) Create a DataFrame for future covariates by mapping each future month to its climatology\n",
    "        # df_future = pd.DataFrame(index=future_idx)\n",
    "\n",
    "        # # For each covariate column, fill with the corresponding monthly mean\n",
    "        # for col in monthly_means.columns:\n",
    "        #     df_future[col] = [monthly_means.loc[m, col] for m in df_future.index.month]\n",
    "\n",
    "        # # 4) Convert to a Darts TimeSeries\n",
    "        # full_df = pd.concat([covariates.pd_dataframe(), df_future])\n",
    "        # future_covariates = TimeSeries.from_dataframe(full_df)\n",
    "        # future_covariates = TimeSeries.from_dataframe(df_future)\n",
    "        # Forecast to 2050\n",
    "        # horizon = (pd.Timestamp(\"2050-12-01\") - target_series.end_time()).days // 30\n",
    "        # future = best.predict(horizon, series=target_series,future_covariates=future_covariates)\n",
    "        # future = best.predict(horizon, series=target_series)\n",
    "\n",
    "\n",
    "        # if not isinstance(future.time_index, pd.DatetimeIndex):\n",
    "        #     future = TimeSeries.from_times_and_values(\n",
    "        #         pd.date_range(\n",
    "        #             start=target_series.end_time() + pd.DateOffset(months=1),\n",
    "        #             periods=len(future),\n",
    "        #             freq=\"MS\"\n",
    "        #         ),\n",
    "        #         future.values(),\n",
    "        #         columns=target_series.components\n",
    "        #     )\n",
    "\n",
    "        # historical = target_series\n",
    "        # full_series = historical.append(future)\n",
    "\n",
    "        # plt.figure(figsize=(12, 4))\n",
    "        # full_series.plot(label=\"SPI\")\n",
    "        # plt.axvline(x=historical.end_time(), color='r', linestyle='--', label=\"Forecast Start\")\n",
    "        # plt.title(f\"Forecast 2050 {st} | {ts}: {best_model}\")\n",
    "\n",
    "        # plt.xlabel(\"Time\")\n",
    "        # plt.ylabel(\"SPI\")\n",
    "        # plt.grid(True)\n",
    "        # plt.legend()\n",
    "        # plt.tight_layout()\n",
    "        # plt.savefig(os.path.join(model_folder, f\"{st}/Forecast_{ts}.png\"))\n",
    "        # plt.show()\n",
    "\n",
    "# spi_df = future.pd_dataframe().reset_index()\n",
    "        # spi_df['year'] = pd.to_datetime(spi_df['date']).dt.year\n",
    "        # spi_df['month'] = pd.to_datetime(spi_df['date']).dt.month\n",
    "\n",
    "        # # SPI heatmap\n",
    "        # heatmap_data = spi_df.pivot_table(index='year', columns='month', values=\"spi_deseason\")\n",
    "        # plt.figure(figsize=(12, 8))\n",
    "        # sns.heatmap(heatmap_data, cmap='rocket', center=0, annot=True, fmt=\".2f\")\n",
    "        # plt.title(f\"SPI Heatmap — {ts} — {st}\")\n",
    "        # plt.xlabel(\"Month\")\n",
    "        # plt.ylabel(\"Year\")\n",
    "        # plt.tight_layout()\n",
    "        # plt.grid(False)\n",
    "        # plt.savefig(os.path.join(base_dir, f\"{st}/heatmap_{ts}.png\"))\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        # spi_df['category'] = pd.cut(spi_df[\"spi_deseason\"], bins=[-np.inf, -1, 1, np.inf], labels=['Dry', 'Normal', 'Wet'])\n",
    "        # colors = {'Dry': 'red', 'Normal': 'gray', 'Wet': 'blue'}\n",
    "\n",
    "        # plt.figure(figsize=(14, 6))\n",
    "        # for category, color in colors.items():\n",
    "        #     mask = spi_df['category'] == category\n",
    "        #     plt.scatter(spi_df['date'][mask], spi_df['spi_deseason'][mask], c=color, label=category)\n",
    "\n",
    "        # plt.axhline(0, color='black', lw=1, linestyle='--')\n",
    "        # plt.title(f\"SPI Categories: Dry / Normal / Wet — {st} | {ts}\")\n",
    "        # plt.xlabel(\"Date\")\n",
    "        # plt.ylabel(\"SPI Value\")\n",
    "        # plt.grid(True)\n",
    "        # plt.tight_layout()\n",
    "        # plt.legend()\n",
    "        # plt.savefig(os.path.join(base_dir, f\"{st}/scatter_{ts}.png\"))\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "        # # Use a simple threshold detector\n",
    "        # detector = ThresholdAD(low_threshold=-1.5, high_threshold=1.5)\n",
    "        # anomalies = detector.detect(full_series)\n",
    "\n",
    "        # # Plot\n",
    "        # full_series.plot(label=\"SPI\")\n",
    "        # anomalies.plot(label=\"Anomalies\", color='red', marker='o')\n",
    "        # plt.legend()\n",
    "        # plt.title(f\"Darts Anomaly Detection — {station_id} | {col}\")\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478a3e1",
   "metadata": {},
   "source": [
    "Loop over stations & timescales, \n",
    " forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf9ee0",
   "metadata": {},
   "source": [
    "then auto slide creation or pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_path = os.path.join(base_dir, \"SPI_Results_Summary.pptx\")\n",
    "prs = Presentation()\n",
    "\n",
    "title_slide_layout = prs.slide_layouts[0]\n",
    "blank_slide_layout = prs.slide_layouts[6]\n",
    "\n",
    "# Title slide\n",
    "slide = prs.slides.add_slide(title_slide_layout)\n",
    "slide.shapes.title.text = \"SPI Forecast & Evaluation Summary\"\n",
    "# slide.placeholders[1].text = \"Auto-generated using python-pptx\\nIncludes Taylor Diagrams, Heatmaps, Model Metrics & Forecasts\"\n",
    "\n",
    "# image_summaries = {\n",
    "#     \"val_vs_pred\": \"Comparison of predicted vs. actual SPI values. Good alignment indicates accurate forecasting.\",\n",
    "#     \"heatmap\": \"Heatmap of forecast performance over time. Brighter regions indicate higher error or uncertainty.\",\n",
    "#     \"taylor\": \"Taylor diagram summarizing model skill. Closer proximity to reference indicates better performance.\",\n",
    "#     \"scatter\": \"Scatter plot of predicted vs. observed SPI. Closer points to diagonal line show better predictions.\"\n",
    "# }\n",
    "\n",
    "def generate_summary(img_type, model_metrics):\n",
    "    \"\"\"Create a smart summary based on image type and model metrics.\"\"\"\n",
    "    if not model_metrics:\n",
    "        return \"Performance data not available.\"\n",
    "\n",
    "    # Pick the best model based on RMSE (you can use another metric too)\n",
    "    best_model, (std_o, std_p, corr, rmse, mape,sm) = min(model_metrics.items(), key=lambda x: x[1][3])  # sort by RMSE\n",
    "\n",
    "    # Interpret performance\n",
    "    if rmse < 0.3 and mape < 10 and corr > 0.85:\n",
    "        perf = \"excellent\"\n",
    "    elif rmse < 0.6 and mape < 20 and corr > 0.65:\n",
    "        perf = \"reasonable\"\n",
    "    else:\n",
    "        perf = \"poor\"\n",
    "\n",
    "    # Now create summaries\n",
    "    if img_type == \"val_vs_pred\":\n",
    "        return f\"Predicted vs. observed SPI using {best_model}. Alignment is {perf}, with RMSE={rmse:.2f}, Corr={corr:.2f}.\"\n",
    "    elif img_type == \"heatmap\":\n",
    "        return f\"Heatmap of error over time for {best_model}. Performance is {perf}, with average MAPE={mape:.1f}%.\"\n",
    "    elif img_type == \"taylor\":\n",
    "        return f\"Taylor diagram showing model spread vs. observed. {best_model} shows {perf} alignment with reference point.\"\n",
    "    elif img_type == \"scatter\":\n",
    "        return f\"Scatter plot for {best_model}. {perf.capitalize()} correlation between predictions and observations (Corr={corr:.2f}).\"\n",
    "    else:\n",
    "        return \"Performance visualization.\"\n",
    "\n",
    "# Loop through all stations\n",
    "for station_id in sorted(os.listdir(base_dir)):\n",
    "    station_path = os.path.join(base_dir, station_id)\n",
    "    if not os.path.isdir(station_path):\n",
    "        continue\n",
    "\n",
    "    for col in results.get(int(station_id), {}):  # Ensure `station_id` matches results keys\n",
    "        # Add slide for this station/SPI\n",
    "        slide = prs.slides.add_slide(blank_slide_layout)\n",
    "        # Add title\n",
    "        title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(9), Inches(0.5))\n",
    "        tf = title_box.text_frame\n",
    "        tf.text = f\"Station {station_id} — {col}\"\n",
    "        tf.paragraphs[0].font.size = Pt(24)\n",
    "        tf.paragraphs[0].font.bold = True\n",
    "\n",
    "        # Add metrics table\n",
    "        metrics = results[int(station_id)][col]\n",
    "        rows, cols = len(metrics) + 1, 6\n",
    "        table = slide.shapes.add_table(rows, cols, Inches(0.5), Inches(1), Inches(8), Inches(0.6 + rows * 0.4)).table\n",
    "        table.cell(0, 0).text = \"Model\"\n",
    "        table.cell(0, 1).text = \"RMSE\"\n",
    "        table.cell(0, 2).text = \"MAPE\"\n",
    "        table.cell(0, 3).text = \"Corr\"\n",
    "        table.cell(0, 4).text = \"Std. Dev (Pred)\"\n",
    "        table.cell(0, 5).text = \"smape\"\n",
    "\n",
    "        for i, (model_name, (std_o, std_p, corr, rmse, mape,sm)) in enumerate(metrics.items(), start=1):\n",
    "            table.cell(i, 0).text = model_name\n",
    "            table.cell(i, 1).text = f\"{rmse:.3f}\"\n",
    "            table.cell(i, 2).text = f\"{mape:.2f}%\"\n",
    "            table.cell(i, 3).text = f\"{corr:.2f}\"\n",
    "            table.cell(i, 4).text = f\"{std_p:.2f}\"\n",
    "            table.cell(i, 5).text = f\"{sm:.2f}\"\n",
    "\n",
    "        # Add first two images\n",
    "        # image_files = [\"taylor\",\"val_vs_pred\",  \"heatmap\", \"scatter\"]\n",
    "        image_files = [\"taylor\",\"val_vs_pred\",\"Forecast\", \"heatmap\",  \"scatter\"]\n",
    "        img_slide_count = 0\n",
    "        img_group = []\n",
    "\n",
    "        for img_type in image_files:\n",
    "            img_path = os.path.join(station_path, f\"{img_type}_{col}.png\")\n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "\n",
    "            # Create a new slide for each image\n",
    "            current_slide = prs.slides.add_slide(blank_slide_layout)\n",
    "\n",
    "            # Add slide title\n",
    "            sub_title_box = current_slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(9), Inches(0.5))\n",
    "            sub_tf = sub_title_box.text_frame\n",
    "            sub_tf.text = f\"Station {station_id} — {col} ({img_type.replace('_', ' ').title()})\"\n",
    "            sub_tf.paragraphs[0].font.size = Pt(20)\n",
    "            sub_tf.paragraphs[0].font.bold = True\n",
    "\n",
    "            # Add image\n",
    "            x = Inches(0.5)\n",
    "            y_img = Inches(1.0)\n",
    "            current_slide.shapes.add_picture(img_path, x, y_img, width=Inches(8.5))  # Full width if needed\n",
    "\n",
    "            # Add summary text\n",
    "            y_text = y_img + Inches(5.8)\n",
    "            model_metrics = results[int(station_id)][col]\n",
    "            summary_text = generate_summary(img_type, model_metrics)\n",
    "\n",
    "            textbox = current_slide.shapes.add_textbox(x, y_text, width=Inches(8.5), height=Inches(1))\n",
    "            tf = textbox.text_frame\n",
    "            tf.text = summary_text\n",
    "            tf.paragraphs[0].font.size = Pt(12)\n",
    "\n",
    "        # for img_type in image_files:\n",
    "        #     img_path = os.path.join(station_path, f\"{img_type}_{col}.png\")\n",
    "        #     if os.path.exists(img_path):\n",
    "        #         img_group.append(img_path)\n",
    "\n",
    "        # # Split image group into chunks of 2\n",
    "        # for i in range(0, len(img_group), 2):\n",
    "        #     if i == 0:\n",
    "        #         # Use the first slide already created\n",
    "        #         current_slide = slide\n",
    "        #     else:\n",
    "        #         current_slide = prs.slides.add_slide(blank_slide_layout)\n",
    "\n",
    "        #         # Add title for extra image slides\n",
    "        #         sub_title_box = current_slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(9), Inches(0.5))\n",
    "        #         sub_tf = sub_title_box.text_frame\n",
    "        #         sub_tf.text = f\"Station {station_id} — {col} (Images {i + 1}–{min(i+2, len(img_group))})\"\n",
    "        #         sub_tf.paragraphs[0].font.size = Pt(20)\n",
    "        #         sub_tf.paragraphs[0].font.bold = True\n",
    "\n",
    "        #     for j, img_path in enumerate(img_group[i:i+2]):\n",
    "        #         x = Inches(0.5 + j * 5)  # Side by side\n",
    "        #         y_img  = Inches(2.7 if i == 0 else 1.0)\n",
    "        #         y_text = y_img + Inches(3.6)  # Position text below image\n",
    "        #         current_slide.shapes.add_picture(img_path, x, y_img, width=Inches(4.5))\n",
    "\n",
    "        #         # Extract image type to get its description\n",
    "        #         img_filename = os.path.basename(img_path)\n",
    "        #         img_type = img_filename.split(\"_\")[0]\n",
    "\n",
    "        #         model_metrics = results[int(station_id)][col]\n",
    "        #         summary_text = generate_summary(img_type, model_metrics)\n",
    "\n",
    "\n",
    "        #         textbox = current_slide.shapes.add_textbox(x, y_text, width=Inches(4.5), height=Inches(1))\n",
    "        #         tf = textbox.text_frame\n",
    "        #         tf.text = summary_text\n",
    "        #         tf.paragraphs[0].font.size = Pt(12)\n",
    "\n",
    "# Save presentation\n",
    "prs.save(ppt_path)\n",
    "print(f\"✅ Presentation saved to: {ppt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77d481f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\PredictionDroughtUsingLSTM-\\Codes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680435b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "base_dir = \"all_results\"\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"SPI Forecast & Evaluation Summary\", 0)\n",
    "spi_periods = [\"1\", \"3\", \"6\", \"9\", \"12\", \"24\"]\n",
    "\n",
    "\n",
    "def generate_summary(img_type, model_metrics):\n",
    "    if not model_metrics:\n",
    "        return None\n",
    "\n",
    "    best_model, (std_o, std_p, corr, rmse, mape, sm) = min(model_metrics.items(), key=lambda x: x[1][3])\n",
    "    if rmse < 0.3 and mape < 10 and corr > 0.85:\n",
    "        perf = \"excellent\"\n",
    "    elif rmse < 0.6 and mape < 20 and corr > 0.65:\n",
    "        perf = \"reasonable\"\n",
    "    else:\n",
    "        perf = \"poor\"\n",
    "\n",
    "    if img_type == \"val_vs_pred\":\n",
    "        return f\"{best_model}: RMSE={rmse:.2f}, Corr={corr:.2f} — {perf} performance.\"\n",
    "    elif img_type == \"heatmap\":\n",
    "        return f\"{best_model} temporal map: Avg. MAPE={mape:.1f}% — {perf} performance.\"\n",
    "    elif img_type == \"taylor\":\n",
    "        return f\"{best_model} Taylor diagram — {perf} skill alignment.\"\n",
    "    return None\n",
    "\n",
    "# Inputs\n",
    "image_types  = {\n",
    "    \"taylor\": \"Taylor Diagram\",\n",
    "    \"heatmap\": \"Temporal Map\",\n",
    "    \"val_vs_pred\": \"Validation vs. Prediction\"\n",
    "}\n",
    "\n",
    "# def add_image(doc, img_path, caption, width=Inches(2.9)):\n",
    "#     if not os.path.exists(img_path):\n",
    "#         return\n",
    "#     doc.add_picture(img_path, width=width)\n",
    "#     last_paragraph = doc.paragraphs[-1]\n",
    "#     last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "#     caption_paragraph = doc.add_paragraph(caption)\n",
    "#     caption_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "#     caption_paragraph.style.font.size = Pt(9)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def crop_bottom_whitespace(image_path, save_path=None, crop_ratio=0.3):\n",
    "    \"\"\"Crop the bottom portion of the image.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        cropped_img = img.crop((0, 0, width, int(height * (1 - crop_ratio))))\n",
    "        cropped_img.save(save_path or image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error cropping {image_path}: {e}\")\n",
    "\n",
    "# Loop through station folders\n",
    "for station_id in sorted(os.listdir(base_dir)):\n",
    "    station_path = os.path.join(base_dir, station_id)\n",
    "    if not os.path.isdir(station_path) or not station_id.isdigit():\n",
    "        continue\n",
    "\n",
    "    doc.add_heading(f\"Station {station_id}\", level=1)\n",
    "\n",
    "    for spi in spi_periods:\n",
    "        doc.add_heading(f\"SPI-{spi}\", level=2)\n",
    "\n",
    "        table = doc.add_table(rows=1, cols=3)\n",
    "        table.autofit = True\n",
    "        row = table.rows[0]\n",
    "\n",
    "        for i, prefix in enumerate([\"taylor\", \"heatmap\", \"val_vs_pred\"]):\n",
    "            file_name = f\"{prefix}_SPI_{spi}.png\"\n",
    "            img_path = os.path.join(station_path, file_name)\n",
    "\n",
    "            # Crop white space from Taylor diagram if needed\n",
    "            if prefix == \"taylor\" and os.path.exists(img_path):\n",
    "                crop_bottom_whitespace(img_path)\n",
    "\n",
    "            if os.path.exists(img_path):\n",
    "                paragraph = row.cells[i].paragraphs[0]\n",
    "                run = paragraph.add_run()\n",
    "                run.add_picture(img_path, width=Inches(2.2))\n",
    "                row.cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "        doc.add_paragraph()  # slight space between rows\n",
    "\n",
    "    doc.add_page_break()\n",
    "\n",
    "doc_path = os.path.join(base_dir, \"SPI_Results_Summary.docx\")\n",
    "doc.save(doc_path)\n",
    "print(f\"✅ Word document saved to: {doc_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb6bbd",
   "metadata": {},
   "source": [
    "Iran Stations Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8473505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch, Rectangle\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import Rbf\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.path import Path\n",
    "\n",
    "# === Load shapefiles ===\n",
    "iran = gpd.read_file('materials/iran.shp')   \n",
    "sea = gpd.read_file('materials/seas.shp') \n",
    "\n",
    "# === Load and prepare station data ===\n",
    "stations_df = pd.read_csv('../main_data.csv')\n",
    "stations = stations_df[['station_id', 'station_name', 'station_elevation', 'lat', 'lon']].drop_duplicates()\n",
    "geometry = [Point(xy) for xy in zip(stations['lon'], stations['lat'])]\n",
    "geo_df = gpd.GeoDataFrame(stations, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "buffer = 0.3  # Optional: adds margin around stations\n",
    "xmin, xmax = geo_df.geometry.x.min() - buffer, geo_df.geometry.x.max() + buffer\n",
    "ymin, ymax = geo_df.geometry.y.min() - buffer, geo_df.geometry.y.max() + buffer\n",
    "\n",
    "\n",
    "# === Interpolate elevation ===\n",
    "x = geo_df.geometry.x.values\n",
    "y = geo_df.geometry.y.values\n",
    "z = geo_df['station_elevation'].values\n",
    "grid_res = 500\n",
    "# xi = np.linspace(iran.total_bounds[0], iran.total_bounds[2], grid_res)\n",
    "# yi = np.linspace(iran.total_bounds[1], iran.total_bounds[3], grid_res)\n",
    "xi = np.linspace(xmin, xmax, grid_res)\n",
    "yi = np.linspace(ymin, ymax, grid_res)\n",
    "xi, yi = np.meshgrid(xi, yi)\n",
    "rbf = Rbf(x, y, z, function='linear')\n",
    "zi = rbf(xi, yi)\n",
    "\n",
    "# Create a mask from the Iran polygon\n",
    "iran_shape = iran.unary_union  # In case it's a multi-polygon\n",
    "mask = np.ones_like(zi, dtype=bool)\n",
    "\n",
    "# Build a Path object for masking\n",
    "# iran_path = Path(iran_shape.exterior.coords[:])\n",
    "\n",
    "# Go through each grid point and mask if it's outside\n",
    "for i in range(zi.shape[0]):\n",
    "    for j in range(zi.shape[1]):\n",
    "        point = (xi[0, j], yi[i, 0])  # Get X, Y of this pixel\n",
    "        if iran_shape.contains(Point(point)):\n",
    "            mask[i, j] = False\n",
    "\n",
    "# Apply mask to elevation\n",
    "zi_masked = np.ma.masked_array(zi, mask=mask)\n",
    "\n",
    "# === Define zoom region ===\n",
    "# # Set the zoom box manually for a region (e.g., Ardabil or any other)\n",
    "# zoom_xmin, zoom_xmax = 46.5, 49.5\n",
    "# zoom_ymin, zoom_ymax = 37.0, 39.0\n",
    "\n",
    "# === Setup figure ===\n",
    "fig = plt.figure(figsize=(5, 8))\n",
    "\n",
    "# --- Left: Full map of Iran ---\n",
    "ax_iran = fig.add_axes([0.02, 0.65, 0.5, 0.5])  # Top-left corner\n",
    "sea.plot(ax=ax_iran, color='lightblue')\n",
    "iran.plot(ax=ax_iran, color='lightgray', edgecolor='black')\n",
    "ax_iran.set_xticks([]); ax_iran.set_yticks([]); ax_iran.set_title('Iran Overview', fontsize=12)\n",
    "\n",
    "# # Draw zoom rectangle on Iran map\n",
    "# rect = Rectangle((zoom_xmin, zoom_ymin), zoom_xmax - zoom_xmin, zoom_ymax - zoom_ymin,\n",
    "#                  linewidth=2, edgecolor='red', facecolor='none', linestyle='--')\n",
    "# ax_iran.add_patch(rect)\n",
    "\n",
    "ax_iran.plot([xmin, xmax, xmax, xmin, xmin],\n",
    "             [ymin, ymin, ymax, ymax, ymin],\n",
    "             color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# --- Right: Zoomed-in elevation with stations ---\n",
    "ax_zoom = fig.add_axes([0.02, 0.05, 0.8, 0.8])  # Right side\n",
    "\n",
    "iran.plot(ax=ax_zoom, facecolor='none', edgecolor='black', linewidth=1.2)\n",
    "\n",
    "elev_img = ax_zoom.imshow(zi_masked, extent=(xi.min(), xi.max(), yi.min(), yi.max()),\n",
    "                          origin='lower', cmap='terrain', alpha=0.8)\n",
    "\n",
    "# # Set zoom limits\n",
    "# ax_zoom.set_xlim(zoom_xmin, zoom_xmax)\n",
    "# ax_zoom.set_ylim(zoom_ymin, zoom_ymax)\n",
    "\n",
    "geo_df.plot(ax=ax_zoom, color='black', markersize=20, marker='^', zorder=3)\n",
    "\n",
    "for idx, row in geo_df.iterrows():\n",
    "    ax_zoom.text(row.geometry.x + 0.05, row.geometry.y, \n",
    "                 str(row['station_id']), fontsize=8, color='black')\n",
    "# ax_zoom.set_title('Zoomed Region: Elevation & Stations', fontsize=12)\n",
    "# ax_zoom.set_xticks([]); ax_zoom.set_yticks([])\n",
    "ax_zoom.set_xlim(xmin, xmax)\n",
    "ax_zoom.set_ylim(ymin, ymax)\n",
    "# ax_zoom.set_xticks([]); ax_zoom.set_yticks([])\n",
    "\n",
    "# --- Colorbar ---\n",
    "cbar = fig.colorbar(elev_img, ax=ax_zoom, orientation='vertical', pad=0.09, fraction=0.03)\n",
    "# cbar.set_label('Elevation (m)')\n",
    "\n",
    "# --- Compass Rose (top right of zoom view) ---\n",
    "compass_img = mpimg.imread('materials/vecteezy_nautical-compass-icon_.jpg')\n",
    "ax_compass = fig.add_axes([0.68, 0.77, 0.2, 0.2])  # Adjust position/size here\n",
    "ax_compass.imshow(compass_img)\n",
    "ax_compass.axis('off')  # Hide axes frame\n",
    "ax_compass.set_title(\"N\", fontsize=10, pad=-10)\n",
    "# imagebox = OffsetImage(compass_img, zoom=0.06)\n",
    "# ab = AnnotationBbox(imagebox, (0.91, 0.91), xycoords='axes fraction', frameon=False,)\n",
    "# ax_zoom.add_artist(ab)\n",
    "\n",
    "# --- Add lines from Iran map to zoomed region ---\n",
    "# Calculate rectangle corners\n",
    "corner1 = (xmin, ymin)\n",
    "corner2 = (xmax, ymax)\n",
    "\n",
    "# Line from bottom-left corner of zoom box\n",
    "con1 = ConnectionPatch(xyA=corner1, xyB=corner1, coordsA=\"data\", coordsB=\"data\",\n",
    "                       axesA=ax_iran, axesB=ax_zoom, color=\"red\", linestyle='--')\n",
    "fig.add_artist(con1)\n",
    "\n",
    "# Line from top-right corner of zoom box\n",
    "con2 = ConnectionPatch(xyA=corner2, xyB=corner2, coordsA=\"data\", coordsB=\"data\",\n",
    "                       axesA=ax_iran, axesB=ax_zoom, color=\"red\", linestyle='--')\n",
    "fig.add_artist(con2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"iran_stations.png\", dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e069888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"../main_data.csv\")\n",
    "\n",
    "# Group by station and calculate averages\n",
    "summary = df.groupby(['station_id', 'station_name', 'region_name', 'station_elevation'])[\n",
    "    ['tm_m', 'tmax_m', 'tmin_m', 'rrr24']\n",
    "].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "summary.columns = [\n",
    "    'Station ID', 'Station Name', 'Region', 'Elevation (m)',\n",
    "    'Avg Temp (°C)', 'Avg Max Temp (°C)', 'Avg Min Temp (°C)', 'Avg Rainfall (mm/month)'\n",
    "]\n",
    "\n",
    "# Optional: Export to Excel or Word\n",
    "summary.to_excel(\"climate_summary.xlsx\", index=False)\n",
    "\n",
    "# Or, export to Word using python-docx (optional)\n",
    "from docx import Document\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading('Climate Summary of Stations', 0)\n",
    "\n",
    "table = doc.add_table(rows=1, cols=len(summary.columns))\n",
    "table.style = 'Table Grid'\n",
    "\n",
    "# Add headers\n",
    "hdr_cells = table.rows[0].cells\n",
    "for i, column in enumerate(summary.columns):\n",
    "    hdr_cells[i].text = column\n",
    "\n",
    "# Add data rows\n",
    "for _, row in summary.iterrows():\n",
    "    row_cells = table.add_row().cells\n",
    "    for i, item in enumerate(row):\n",
    "        row_cells[i].text = str(round(item, 2)) if isinstance(item, float) else str(item)\n",
    "\n",
    "doc.save(\"climate_summary.docx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
